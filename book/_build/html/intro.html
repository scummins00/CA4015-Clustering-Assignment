
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Clustering Assignment</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-2 bd-sidebar site-navigation show single-page" id="site-navigation">
    
</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            
            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fintro.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#document-data_prep">
   Data Cleaning
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#data-preperation">
   Data Preperation
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#document-Naive_Clustering_of_Total_Dataset">
   Clustering of Total Dataset (Net Win by Net Loss)
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#initial-setup">
   Initial Setup
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#kmeans-clustering-of-net-win-net-loss">
   KMeans Clustering of Net Win &amp; Net Loss
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#comparison-between-opposite-groups">
   Comparison Between Opposite Groups
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#comparison-of-all-clusters">
   Comparison of All Clusters
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#document-clustering_total_dataset_2">
   Clustering of Total Dataset 2 (10% Intervals)
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#k-means-clustering">
   K-Means Clustering
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#document-federated_clustering">
   Federated Clustering Approach (10% Intervals)
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#packages">
   Packages
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#data-loading">
   Data Loading
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#k-means-clustering">
   K-Means Clustering
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#document-conclusion">
   Conclusion
  </a>
 </li>
 <li class="toctree-l1 toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="intro.html#document-bibliography">
   Bibliography
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="ca4015-clustering-assignment-introduction">
<h1>CA4015 Clustering Assignment Introduction<a class="headerlink" href="#ca4015-clustering-assignment-introduction" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<div class="section" id="introduction-to-the-iowa-gambling-task">
<h2>Introduction to the Iowa Gambling Task<a class="headerlink" href="#introduction-to-the-iowa-gambling-task" title="Permalink to this headline">¶</a></h2>
<p>This Jupyter Book will hold an analysis of data from 617 Healthy Participants Performing the <strong><em>Iowa Gambling Task</em></strong> (IGT). The data, which originates from 10 individual studies, is pooled together by <span id="id1">[<a class="reference internal" href="intro.html#id3">Steingroever <em>et al.</em>, 2015</a>]</span>. All participants are healthy (have no known neurological impairments). Participants were assessed on a computerised version of the IGT. The playing conditions vary between each study, with participant’s attempts ranging between <em>95 - 150 tries</em>. The <em>payoff scheme</em> varies also, with some servers hosting <strong>harsher penalties</strong> and <strong>more lucrative rewards</strong>.</p>
</div>
<div class="section" id="introduction-to-k-means-clustering-algorithm">
<h2>Introduction to K-Means Clustering Algorithm<a class="headerlink" href="#introduction-to-k-means-clustering-algorithm" title="Permalink to this headline">¶</a></h2>
<p><strong><em>K-Means Clustering</em></strong> is a classical machine learning algorithm developed well over 50 years ago. K-Means is an <em>unsupervised</em> machine learning technique meaning, unlike classification it does not need to be trained on annotated training data. Although K-Means is a rhobust algorithm, it does suffer from the ‘curse of dimensionality’. This means that techniques such as <em>Principal Component Analysis</em> are commonly used in conjunction with K-Means to perform dimensionality reduction.</p>
</div>
<div class="section" id="introduction-to-federated-learning">
<h2>Introduction to Federated Learning<a class="headerlink" href="#introduction-to-federated-learning" title="Permalink to this headline">¶</a></h2>
<p><strong><em>Federated Learning</em></strong> (FL) is a deep learning approach which involves training a model over disconnected or siloed data centres such as mobile phones. Rather than both the data and model being centralised on one system, data is preserved in its local environment. A machine learning model is sent to the system hosting the data, rather than the reverse. This approach makes a step forward in protecting the privacy of user-generated data. In FL, the user data is not transmitted across a network. However, there are challenges associated with FL, including: <em>the expensive nature</em>, <em>system heterogeneity</em>, <em>statistical heterogeneity</em>, and <em>privacy</em> <span id="id2">[<a class="reference internal" href="intro.html#id14">Li <em>et al.</em>, 2020</a>]</span>.</p>
</div>
<div class="section" id="dataset-description">
<h2>Dataset Description<a class="headerlink" href="#dataset-description" title="Permalink to this headline">¶</a></h2>
<p>As stated previously, the data originates from 10 individual studies. These studies can be found listed below:</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>Study</p></th>
<th class="text-align:center head"><p>Amount of Participants</p></th>
<th class="text-align:center head"><p>Number of Trials</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><span id="id3">[<a class="reference internal" href="intro.html#id4">Fridberg <em>et al.</em>, 2010</a>]</span></p></td>
<td class="text-align:center"><p>15</p></td>
<td class="text-align:center"><p>95</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p><span id="id4">[<a class="reference internal" href="intro.html#id5">Horstmann <em>et al.</em>, 2012</a>]</span></p></td>
<td class="text-align:center"><p>162</p></td>
<td class="text-align:center"><p>100</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p><span id="id5">[<a class="reference internal" href="intro.html#id6">Kjome <em>et al.</em>, 2010</a>]</span></p></td>
<td class="text-align:center"><p>19</p></td>
<td class="text-align:center"><p>100</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p><span id="id6">[<a class="reference internal" href="intro.html#id7">Maia and McClelland, 2004</a>]</span></p></td>
<td class="text-align:center"><p>40</p></td>
<td class="text-align:center"><p>100</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p><span id="id7">[<a class="reference internal" href="intro.html#id8">Premkumar <em>et al.</em>, 2008</a>]</span></p></td>
<td class="text-align:center"><p>25</p></td>
<td class="text-align:center"><p>100</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p><span id="id8">[<a class="reference internal" href="intro.html#id9">Steingroever <em>et al.</em>, 2011</a>]</span></p></td>
<td class="text-align:center"><p>70</p></td>
<td class="text-align:center"><p>100</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p><span id="id9">[<a class="reference internal" href="intro.html#id10">Steingroever <em>et al.</em>, 2011</a>]</span></p></td>
<td class="text-align:center"><p>57</p></td>
<td class="text-align:center"><p>150</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p><span id="id10">[<a class="reference internal" href="intro.html#id11">Wetzels <em>et al.</em>, 2010</a>]</span></p></td>
<td class="text-align:center"><p>41</p></td>
<td class="text-align:center"><p>150</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p><span id="id11">[<a class="reference internal" href="intro.html#id12">Wood <em>et al.</em>, 2005</a>]</span></p></td>
<td class="text-align:center"><p>153</p></td>
<td class="text-align:center"><p>100</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p><span id="id12">[<a class="reference internal" href="intro.html#id13">Worthy <em>et al.</em>, 2013</a>]</span></p></td>
<td class="text-align:center"><p>35</p></td>
<td class="text-align:center"><p>100</p></td>
</tr>
</tbody>
</table>
<div class="section" id="quality-control">
<h3>Quality Control<a class="headerlink" href="#quality-control" title="Permalink to this headline">¶</a></h3>
<p>All studies were administered through a computerized version of the IGT to ensure quality <span id="id13">[<a class="reference internal" href="intro.html#id3">Steingroever <em>et al.</em>, 2015</a>]</span>.</p>
</div>
</div>
<div class="toctree-wrapper compound">
<span id="document-data_prep"></span><div class="section" id="data-cleaning">
<h2>Data Cleaning<a class="headerlink" href="#data-cleaning" title="Permalink to this headline">¶</a></h2>
<p>In the following Notebook, we will verify the integrity of our data. The data provided by 10 individual studies and centralised by <span id="id1">[<a class="reference internal" href="intro.html#id3">Steingroever <em>et al.</em>, 2015</a>]</span>, is inherently clean and ready for use. To ensure this, we will perform the following verification steps:</p>
<ol class="simple">
<li><p>Test all datasets for any missing values.</p></li>
<li><p>Verify that deck choice datasets do not host cells exceding a maximum value of 4 and a minimum value of 1.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#importing packages</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Reading in the data</span>
<span class="n">sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#choices</span>
<span class="n">choice_95</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/choice_95.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">choice_95</span><span class="p">)</span>
<span class="n">choice_100</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/choice_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">choice_100</span><span class="p">)</span>
<span class="n">choice_150</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/choice_150.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">choice_150</span><span class="p">)</span>

<span class="c1">#Losses</span>
<span class="n">loss_95</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/lo_95.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_95</span><span class="p">)</span>
<span class="n">loss_100</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/lo_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_100</span><span class="p">)</span>
<span class="n">loss_150</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/lo_150.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_150</span><span class="p">)</span>
<span class="c1">#Wins</span>
<span class="n">win_95</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/wi_95.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">win_95</span><span class="p">)</span>
<span class="n">win_100</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/wi_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">win_100</span><span class="p">)</span>
<span class="n">win_150</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/wi_150.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">win_150</span><span class="p">)</span>

<span class="c1">#Index</span>
<span class="n">index_95</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/index_95.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index_95</span><span class="p">)</span>
<span class="n">index_100</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/index_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index_100</span><span class="p">)</span>
<span class="n">index_150</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/index_150.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index_150</span><span class="p">)</span>

<span class="k">for</span> <span class="nb">set</span> <span class="ow">in</span> <span class="n">sets</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NaN value detected: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">set</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">any</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NaN value detected: False
NaN value detected: False
NaN value detected: False
NaN value detected: False
NaN value detected: False
NaN value detected: False
NaN value detected: False
NaN value detected: False
NaN value detected: False
NaN value detected: False
NaN value detected: False
NaN value detected: False
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s view the statitics for our choice datasets to verify min &amp; max values</span>
<span class="p">(</span><span class="n">choice_100</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>min    1.0
max    4.0
dtype: float64
</pre></div>
</div>
</div>
</div>
<p><strong>Note: This part of data exploration is simple by nature, but generates a large output. For simplicity, I have only included the verification of the small choice_100 dataset.</strong></p>
</div>
<div class="section" id="data-preperation">
<h2>Data Preperation<a class="headerlink" href="#data-preperation" title="Permalink to this headline">¶</a></h2>
<p>In section 4 of this book, we will be performing K-Means clustering based on a participant’s cumulative win and loss over the course of the game with results measured in 10% intervals of completion. That is to say, <strong>we measure a participants net score every 10 turns in the case of a participant with 100 total turns</strong>.</p>
<p>In the case of participants with 150 attempts, every <strong>15 consecutive attempts will be condensed into a singular value</strong>.</p>
<p>In the case of participants with 95 attempts, some calculation will be required to aggregate data points together and obtain a mean value. This is required as <em>10% of 95 is 9.5</em>. Clearly we cannot measure the 9.5th turn. This means we will measure <strong>the mean of the 9th and 10th turn</strong>.</p>
<p>To do this, our data requires some <strong>Feature Engineering</strong>. We require a new dataset consisting of the scores described above <em>per participant</em>. Also, in Section 5, we will be performing the same analysis, but with a <strong>Federated Learning</strong> approach. This means that one large dataset will not suffice. For each of the original datasets provided we must:</p>
<ol class="simple">
<li><p>Create and fill our rolling score datasets</p></li>
<li><p>Divide the data out into their individual surveys</p></li>
</ol>
<div class="section" id="creating-rolling-dataframes">
<h3>Creating Rolling Dataframes<a class="headerlink" href="#creating-rolling-dataframes" title="Permalink to this headline">¶</a></h3>
<p>The creation of Dataframes to hold rolling cumulative sumations of values across periods of 10 &amp; 15 attempts for the surveys allowing 100 &amp; 150 attempts respectfully is a painless process.</p>
<p>However, this is not the case with the survey offering 95 attempts as 95 is an uneven number meaning it does not divide easily into equally sized portions. As a consequence of this, the processing steps for the 95 dataset are much more complex.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#We will use pandas.DataFrame.cumsum() to calculate our cumulative sum</span>

<span class="n">rolling_win_100</span><span class="o">=</span><span class="p">(</span><span class="n">win_100</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">)]</span>
<span class="n">rolling_loss_100</span><span class="o">=</span><span class="p">(</span><span class="n">loss_100</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">10</span><span class="p">)]</span>

<span class="n">rolling_win_150</span><span class="o">=</span><span class="p">(</span><span class="n">win_150</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">150</span><span class="p">,</span><span class="mi">15</span><span class="p">)]</span>
<span class="n">rolling_loss_150</span><span class="o">=</span><span class="p">(</span><span class="n">loss_150</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">150</span><span class="p">,</span><span class="mi">15</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#The rolling values for the 95 sets are more difficult as 95 is not divisible by 10</span>
<span class="n">inter_95</span><span class="o">=</span><span class="p">(</span><span class="n">win_95</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,[</span><span class="mi">9</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">37</span><span class="p">,</span><span class="mi">46</span><span class="p">,</span><span class="mi">47</span><span class="p">,</span><span class="mi">56</span><span class="p">,</span><span class="mi">65</span><span class="p">,</span><span class="mi">66</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span><span class="mi">84</span><span class="p">,</span><span class="mi">85</span><span class="p">,</span> <span class="mi">94</span><span class="p">]]</span>

<span class="c1">#Finding the rolling sum for 9th column</span>
<span class="n">wins_95_col8</span><span class="o">=</span><span class="p">(</span><span class="n">win_95</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span>

<span class="c1">#Calculating the average of intermediate columns as new column</span>
<span class="n">Wins_9_5</span><span class="o">=</span><span class="p">(</span><span class="n">wins_95_col8</span><span class="o">+</span><span class="n">inter_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
<span class="n">Wins_28_5</span><span class="o">=</span><span class="p">(</span><span class="n">inter_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="n">inter_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">3</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
<span class="n">Wins_47_5</span><span class="o">=</span><span class="p">(</span><span class="n">inter_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">5</span><span class="p">]</span><span class="o">+</span><span class="n">inter_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">6</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
<span class="n">Wins_66_5</span><span class="o">=</span><span class="p">(</span><span class="n">inter_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span><span class="o">+</span><span class="n">inter_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">9</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
<span class="n">Wins_85_5</span><span class="o">=</span><span class="p">(</span><span class="n">inter_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">11</span><span class="p">]</span><span class="o">+</span><span class="n">inter_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">12</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>

<span class="c1">#Add everything together</span>
<span class="n">inter_win_95</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">inter_95</span><span class="p">,</span> <span class="n">Wins_9_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Wins_9_5&quot;</span><span class="p">),</span> <span class="n">Wins_28_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Wins_28_5&quot;</span><span class="p">),</span> 
                        <span class="n">Wins_47_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Wins_47_5&quot;</span><span class="p">),</span><span class="n">Wins_66_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Wins_66_5&quot;</span><span class="p">),</span>
                        <span class="n">Wins_85_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Wins_85_5&quot;</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1">#Reorganise columns</span>
<span class="n">cols</span> <span class="o">=</span> <span class="n">inter_win_95</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">rolling_win_95</span> <span class="o">=</span> <span class="n">inter_win_95</span><span class="p">[[</span><span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">13</span><span class="p">]]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Now we must do the same for the Losses</span>
<span class="c1">#The rolling values for the 95 sets are more difficult as 95 is not divisible by 10</span>
<span class="n">inter_loss_95</span><span class="o">=</span><span class="p">(</span><span class="n">loss_95</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,[</span><span class="mi">9</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">37</span><span class="p">,</span><span class="mi">46</span><span class="p">,</span><span class="mi">47</span><span class="p">,</span><span class="mi">56</span><span class="p">,</span><span class="mi">65</span><span class="p">,</span><span class="mi">66</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span><span class="mi">84</span><span class="p">,</span><span class="mi">85</span><span class="p">,</span> <span class="mi">94</span><span class="p">]]</span>

<span class="c1">#Finding the rolling sum for 9th column</span>
<span class="n">losses_95_col8</span><span class="o">=</span><span class="p">(</span><span class="n">loss_95</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span>

<span class="c1">#Calculating the average of intermediate columns as new column</span>
<span class="n">Losses_9_5</span><span class="o">=</span><span class="p">(</span><span class="n">losses_95_col8</span><span class="o">+</span><span class="n">inter_loss_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
<span class="n">Losses28_5</span><span class="o">=</span><span class="p">(</span><span class="n">inter_loss_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="n">inter_loss_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">3</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
<span class="n">Losses47_5</span><span class="o">=</span><span class="p">(</span><span class="n">inter_loss_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">5</span><span class="p">]</span><span class="o">+</span><span class="n">inter_loss_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">6</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
<span class="n">Losses66_5</span><span class="o">=</span><span class="p">(</span><span class="n">inter_loss_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">8</span><span class="p">]</span><span class="o">+</span><span class="n">inter_loss_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">9</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
<span class="n">Losses85_5</span><span class="o">=</span><span class="p">(</span><span class="n">inter_loss_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">11</span><span class="p">]</span><span class="o">+</span><span class="n">inter_loss_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">12</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>

<span class="c1">#Add everything together</span>
<span class="n">inter_loss_95</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">inter_loss_95</span><span class="p">,</span> <span class="n">Losses_9_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Losses_9_5&quot;</span><span class="p">),</span> <span class="n">Losses28_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Losses28_5&quot;</span><span class="p">),</span> 
                        <span class="n">Losses47_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Losses47_5&quot;</span><span class="p">),</span><span class="n">Losses66_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Losses66_5&quot;</span><span class="p">),</span>
                        <span class="n">Losses85_5</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s2">&quot;Losses85_5&quot;</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1">#Reorganise columns</span>
<span class="n">cols</span> <span class="o">=</span> <span class="n">inter_loss_95</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">rolling_loss_95</span> <span class="o">=</span> <span class="n">inter_loss_95</span><span class="p">[[</span><span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">cols</span><span class="p">[</span><span class="mi">13</span><span class="p">]]]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="seperate-data-by-study">
<h3>Seperate Data by Study<a class="headerlink" href="#seperate-data-by-study" title="Permalink to this headline">¶</a></h3>
<p>We will now seperate our data by study. We can achieve this by using our <code class="docutils literal notranslate"><span class="pre">index</span></code> files which allows us to seperate our subjects row-wise. We will do the following:</p>
<ol class="simple">
<li><p>Append our index value as a new column</p></li>
<li><p>Group our data by this new column</p></li>
<li><p>Select each study as a subset and create a new DataFrame</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#List for sub sets</span>
<span class="n">finished_sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#List for full sets</span>
<span class="n">full_sets</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="larger-rolling-datasets">
<h4>Larger Rolling Datasets<a class="headerlink" href="#larger-rolling-datasets" title="Permalink to this headline">¶</a></h4>
<p>While the seperated studies will be beneficial for the federated learning approach, it is important to keep the aggregated datasets also.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Wins</span>
<span class="n">full_rolling_wins_95</span> <span class="o">=</span><span class="n">rolling_win_95</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_95</span><span class="p">)</span>
<span class="n">full_rolling_wins_100</span> <span class="o">=</span><span class="n">rolling_win_100</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_100</span><span class="p">)</span>
<span class="n">full_rolling_wins_150</span> <span class="o">=</span><span class="n">rolling_win_150</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_150</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_rolling_wins_95</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_rolling_wins_100</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_rolling_wins_150</span><span class="p">)</span>

<span class="c1">#losses</span>
<span class="n">full_rolling_losses_95</span><span class="o">=</span><span class="n">rolling_loss_95</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_95</span><span class="p">)</span>
<span class="n">full_rolling_losses_100</span><span class="o">=</span><span class="n">rolling_loss_100</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_100</span><span class="p">)</span>
<span class="n">full_rolling_losses_150</span><span class="o">=</span><span class="n">rolling_loss_150</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_150</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_rolling_losses_95</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_rolling_losses_100</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_rolling_losses_150</span><span class="p">)</span>

<span class="c1">#Choices</span>
<span class="n">full_rolling_choices_95</span><span class="o">=</span><span class="n">choice_95</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_95</span><span class="p">)</span>
<span class="n">full_rolling_choices_100</span><span class="o">=</span><span class="n">choice_100</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_100</span><span class="p">)</span>
<span class="n">full_rolling_choices_150</span><span class="o">=</span><span class="n">choice_150</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_150</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_rolling_choices_95</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_rolling_choices_100</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_rolling_choices_150</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-95-dataset">
<h4>The 95 Dataset:<a class="headerlink" href="#the-95-dataset" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Wins</span>
<span class="n">Fridberg_rolling_wins_95</span><span class="o">=</span><span class="n">rolling_win_95</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_95</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Fridberg_rolling_wins_95</span><span class="p">)</span>

<span class="c1">#Losses</span>
<span class="n">Fridberg_rolling_losses_95</span><span class="o">=</span><span class="n">rolling_loss_95</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_95</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Fridberg_rolling_losses_95</span><span class="p">)</span>

<span class="c1">#Choices</span>
<span class="n">Fridberg_choices_95</span><span class="o">=</span><span class="n">choice_95</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_95</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Fridberg_choices_95</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-100-dataset">
<h4>The 100 dataset:<a class="headerlink" href="#the-100-dataset" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Wins</span>
<span class="n">grouped_wins_100</span> <span class="o">=</span> <span class="n">rolling_win_100</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_100</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Study&quot;</span><span class="p">)</span>

<span class="n">Horstmann_rolling_wins_100</span><span class="o">=</span><span class="n">grouped_wins_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Horstmann&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Horstmann_rolling_wins_100</span><span class="p">)</span>

<span class="n">Kjome_rolling_wins_100</span><span class="o">=</span><span class="n">grouped_wins_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Kjome&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Kjome_rolling_wins_100</span><span class="p">)</span>

<span class="n">Maia_rolling_wins_100</span><span class="o">=</span><span class="n">grouped_wins_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Maia&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Maia_rolling_wins_100</span><span class="p">)</span>

<span class="n">SteingroverInPrep_rolling_wins_100</span><span class="o">=</span><span class="n">grouped_wins_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;SteingroverInPrep&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SteingroverInPrep_rolling_wins_100</span><span class="p">)</span>

<span class="n">Premkumar_rolling_wins_100</span><span class="o">=</span><span class="n">grouped_wins_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Premkumar&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Premkumar_rolling_wins_100</span><span class="p">)</span>

<span class="n">Wood_rolling_wins_100</span><span class="o">=</span><span class="n">grouped_wins_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Wood&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Wood_rolling_wins_100</span><span class="p">)</span>

<span class="n">Worthy_rolling_wins_100</span><span class="o">=</span><span class="n">grouped_wins_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Worthy&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Worthy_rolling_wins_100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Losses</span>
<span class="n">grouped_losses_100</span> <span class="o">=</span> <span class="n">rolling_loss_100</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_100</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Study&quot;</span><span class="p">)</span>

<span class="n">Horstmann_rolling_losses_100</span><span class="o">=</span><span class="n">grouped_losses_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Horstmann&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Horstmann_rolling_losses_100</span><span class="p">)</span>

<span class="n">Kjome_rolling_losses_100</span><span class="o">=</span><span class="n">grouped_losses_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Kjome&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Kjome_rolling_losses_100</span><span class="p">)</span>

<span class="n">Maia_rolling_losses_100</span><span class="o">=</span><span class="n">grouped_losses_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Maia&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Maia_rolling_losses_100</span><span class="p">)</span>

<span class="n">SteingroverInPrep_rolling_losses_100</span><span class="o">=</span><span class="n">grouped_losses_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;SteingroverInPrep&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SteingroverInPrep_rolling_losses_100</span><span class="p">)</span>

<span class="n">Premkumar_rolling_losses_100</span><span class="o">=</span><span class="n">grouped_losses_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Premkumar&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Premkumar_rolling_losses_100</span><span class="p">)</span>

<span class="n">Wood_rolling_losses_100</span><span class="o">=</span><span class="n">grouped_losses_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Wood&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Wood_rolling_losses_100</span><span class="p">)</span>

<span class="n">Worthy_rolling_losses_100</span><span class="o">=</span><span class="n">grouped_losses_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Worthy&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Worthy_rolling_losses_100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Choices</span>
<span class="n">grouped_choices_100</span> <span class="o">=</span> <span class="n">choice_100</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_100</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Study&quot;</span><span class="p">)</span>

<span class="n">Horstmann_choices_100</span><span class="o">=</span><span class="n">grouped_choices_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Horstmann&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Horstmann_choices_100</span><span class="p">)</span>

<span class="n">Kjome_choices_100</span><span class="o">=</span><span class="n">grouped_choices_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Kjome&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Kjome_choices_100</span><span class="p">)</span>

<span class="n">Maia_choices_100</span><span class="o">=</span><span class="n">grouped_choices_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Maia&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Maia_choices_100</span><span class="p">)</span>

<span class="n">SteingroverInPrep_choices_100</span><span class="o">=</span><span class="n">grouped_choices_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;SteingroverInPrep&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SteingroverInPrep_choices_100</span><span class="p">)</span>

<span class="n">Premkuma_choices_100</span><span class="o">=</span><span class="n">grouped_choices_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Premkumar&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Premkuma_choices_100</span><span class="p">)</span>

<span class="n">Wood_choices_100</span><span class="o">=</span><span class="n">grouped_choices_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Wood&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Wood_choices_100</span><span class="p">)</span>

<span class="n">Worthy_choices_100</span><span class="o">=</span><span class="n">grouped_choices_100</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Worthy&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Worthy_choices_100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-150-dataset">
<h4>The 150 Dataset:<a class="headerlink" href="#the-150-dataset" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Wins</span>
<span class="n">grouped_wins_150</span> <span class="o">=</span> <span class="n">rolling_win_150</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_150</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Study&quot;</span><span class="p">)</span>

<span class="n">Steingroever2011_rolling_wins_150</span><span class="o">=</span><span class="n">grouped_wins_150</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Steingroever2011&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Steingroever2011_rolling_wins_150</span><span class="p">)</span>
<span class="n">Wetzels_rolling_wins_150</span><span class="o">=</span><span class="n">grouped_wins_150</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Wetzels&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Wetzels_rolling_wins_150</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Losses</span>
<span class="n">grouped_losses_150</span> <span class="o">=</span> <span class="n">rolling_loss_150</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_150</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Study&quot;</span><span class="p">)</span>

<span class="n">Steingroever2011_rolling_losses_150</span><span class="o">=</span><span class="n">grouped_losses_150</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Steingroever2011&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Steingroever2011_rolling_losses_150</span><span class="p">)</span>
<span class="n">Wetzels_rolling_losses_150</span><span class="o">=</span><span class="n">grouped_losses_150</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Wetzels&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Wetzels_rolling_losses_150</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Choices</span>
<span class="n">grouped_choices_150</span> <span class="o">=</span> <span class="n">choice_150</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">index_150</span><span class="p">)</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Study&quot;</span><span class="p">)</span>

<span class="n">Steingroever2011_choices_150</span><span class="o">=</span><span class="n">grouped_choices_150</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Steingroever2011&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Steingroever2011_choices_150</span><span class="p">)</span>
<span class="n">Wetzels_choices_150</span><span class="o">=</span><span class="n">grouped_choices_150</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;Wetzels&quot;</span><span class="p">)</span>
<span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Wetzels_choices_150</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="writing-out-data">
<h4>Writing Out Data:<a class="headerlink" href="#writing-out-data" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Writing out full datasets</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">full_sets</span><span class="p">:</span>
    <span class="n">s</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;../data/cleaned/full_</span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Writing out study datasets</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">finished_sets</span><span class="p">:</span>
    <span class="n">s</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;../data/cleaned/</span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">Study</span><span class="o">.</span><span class="n">unique</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">_rolling_</span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h3>
<p>We have now created a total of 39 datasets which are stored in a folder called <code class="docutils literal notranslate"><span class="pre">cleaned</span></code>. These sets consist of 9 full sets describing the amounts participants made and lost over 10% intervals. The other 30 sets are subsets of the larger 9 sets seperated by study.</p>
<p>We will use the larger sets in Section 4 of this book for K-Means Clustering and analysis. The subsets will then be used in Section 5 as part of a Federated Learning approach.</p>
</div>
</div>
<span id="document-Naive_Clustering_of_Total_Dataset"></span><div class="section" id="clustering-of-total-dataset-net-win-by-net-loss">
<h2>Clustering of Total Dataset (Net Win by Net Loss)<a class="headerlink" href="#clustering-of-total-dataset-net-win-by-net-loss" title="Permalink to this headline">¶</a></h2>
<p>In the follownig Jupyter Notebook, we will be clustering and performing some analysis on the total dataset of 617 healthy participants performing the <strong><em>Iowa Gambling Task</em></strong> (IGT). The clustering algorithm we will be using is the <strong>K-Means Algorithm</strong>. In the following analysis, we will not be taking varying testing conditions between studies (such as <em>Reward Scheme</em> and <em>number of attempts</em>) into consideration. We will be analysing users based on their <strong>Net Win <span class="math notranslate nohighlight">\(\times\)</span> Net Loss</strong>.</p>
<p>We will perform the following tasks in this Notebook:</p>
<ol class="simple">
<li><p>Analysis Setup</p></li>
<li><p>Understand Data Distribution</p>
<ul class="simple">
<li><p>Histogram</p></li>
<li><p>QQPlot</p></li>
</ul>
</li>
<li><p>Clustering</p>
<ul class="simple">
<li><p>Finding the Elbow Point (Inertia Reduction)</p></li>
<li><p>K-Means Clustering</p></li>
</ul>
</li>
<li><p>Comparison Between Contrasting Clusters</p>
<ul class="simple">
<li><p>Time-Series Analysis</p></li>
</ul>
</li>
<li><p>Comparison of All Clusters</p>
<ul class="simple">
<li><p>Boxplot</p></li>
</ul>
</li>
</ol>
</div>
<hr class="docutils" />
<div class="section" id="initial-setup">
<h2>Initial Setup<a class="headerlink" href="#initial-setup" title="Permalink to this headline">¶</a></h2>
<div class="section" id="importing-packages">
<h3>Importing Packages<a class="headerlink" href="#importing-packages" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">pearsonr</span>
<span class="kn">from</span> <span class="nn">statsmodels.graphics.gofplots</span> <span class="kn">import</span> <span class="n">qqplot</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">~</span>\<span class="n">AppData</span>\<span class="n">Local</span>\<span class="n">Temp</span><span class="o">/</span><span class="n">ipykernel_18200</span><span class="o">/</span><span class="mf">935022693.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">pearsonr</span>
<span class="ne">----&gt; </span><span class="mi">6</span> <span class="kn">from</span> <span class="nn">statsmodels.graphics.gofplots</span> <span class="kn">import</span> <span class="n">qqplot</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;statsmodels&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="importing-data">
<h3>Importing Data<a class="headerlink" href="#importing-data" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Importing challenge involving 95 attempts</span>
<span class="n">index_95</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/index_95.csv&quot;</span><span class="p">)</span>
<span class="n">choice_95</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/choice_95.csv&quot;</span><span class="p">)</span>
<span class="n">win_95</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/wi_95.csv&quot;</span><span class="p">)</span>
<span class="n">loss_95</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/lo_95.csv&quot;</span><span class="p">)</span>

<span class="c1">#Importing challenge involving 100 attempts</span>
<span class="n">index_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/index_100.csv&quot;</span><span class="p">)</span>
<span class="n">choice_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/choice_100.csv&quot;</span><span class="p">)</span>
<span class="n">win_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/wi_100.csv&quot;</span><span class="p">)</span>
<span class="n">loss_100</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/lo_100.csv&quot;</span><span class="p">)</span>

<span class="c1">#Importing challenge involving 150 attempts</span>
<span class="n">index_150</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/index_150.csv&quot;</span><span class="p">)</span>
<span class="n">choice_150</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/choice_150.csv&quot;</span><span class="p">)</span>
<span class="n">win_150</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/wi_150.csv&quot;</span><span class="p">)</span>
<span class="n">loss_150</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/lo_150.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="merging-data">
<h3>Merging Data<a class="headerlink" href="#merging-data" title="Permalink to this headline">¶</a></h3>
<p>We will firstly merge all of our data together into large csv files representing the index, choice, win, and loss. For now we will ignore the different payoff schemes introduced for different studies.</p>
<p>As the index for the csv’s will no longer be unique, we will ignore it using <code class="docutils literal notranslate"><span class="pre">ignore_index=True</span></code>. This will also result in some NaN values but they <strong>will not</strong> affect our results at this point.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">full_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">index_95</span><span class="p">,</span> <span class="n">index_100</span><span class="p">,</span> <span class="n">index_150</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">full_choice</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">choice_95</span><span class="p">,</span> <span class="n">choice_100</span><span class="p">,</span> <span class="n">choice_150</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">full_win</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">win_95</span><span class="p">,</span> <span class="n">win_100</span><span class="p">,</span> <span class="n">win_150</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">full_loss</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">loss_95</span><span class="p">,</span> <span class="n">loss_100</span><span class="p">,</span> <span class="n">loss_150</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="kmeans-clustering-of-net-win-net-loss">
<h2>KMeans Clustering of Net Win &amp; Net Loss<a class="headerlink" href="#kmeans-clustering-of-net-win-net-loss" title="Permalink to this headline">¶</a></h2>
<p>The first thing we will do is cluster by <strong>Net Win <span class="math notranslate nohighlight">\(\times\)</span> Net Loss</strong> for each participant.</p>
<p>Let’s create a new DF with two columns, net_win &amp; net_loss with each row representing a participant. We need:</p>
<ol class="simple">
<li><p>Array representing net win / loss for each participant</p></li>
<li><p>Suitable dataframe</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Creating our arrays</span>
<span class="n">net_win</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">full_win</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">net_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">full_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Creating and displaying our dataframe</span>
<span class="n">net_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">full_win</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Winnings&quot;</span><span class="p">,</span> <span class="s2">&quot;Losses&quot;</span><span class="p">,</span> <span class="s2">&quot;Final&quot;</span><span class="p">],</span>
             <span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Winnings&quot;</span><span class="p">:</span><span class="n">net_win</span><span class="p">,</span> <span class="s2">&quot;Losses&quot;</span><span class="p">:</span><span class="n">net_loss</span><span class="p">,</span> <span class="s2">&quot;Final&quot;</span><span class="p">:</span><span class="n">net_win</span><span class="o">+</span><span class="n">net_loss</span><span class="p">})</span>
<span class="n">net_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Winnings</th>
      <th>Losses</th>
      <th>Final</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5800.0</td>
      <td>-4650.0</td>
      <td>1150.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7250.0</td>
      <td>-7925.0</td>
      <td>-675.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7100.0</td>
      <td>-7850.0</td>
      <td>-750.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7000.0</td>
      <td>-7525.0</td>
      <td>-525.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6450.0</td>
      <td>-6350.0</td>
      <td>100.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>So now that we have a suitable dataframe consisting of winnnings and losses per participant, it’s time to do some analysis before we begin clustering.</p>
<p>Let’s visualize the data straight away to help us better understand the distribution of our data</p>
<p><strong>Note that we invert the Y axis in the below plot.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Plotting points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">net_df</span><span class="p">[</span><span class="s2">&quot;Winnings&quot;</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="s2">&quot;Losses&quot;</span><span class="p">])</span>

<span class="c1">#Inverting y-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>

<span class="c1">#Axes labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Earnings&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Losses&#39;</span><span class="p">)</span>

<span class="c1">#Plot Title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Net Earnings by Net Loss per Participant&quot;</span><span class="p">)</span>

<span class="c1">#Inserting Pearson Correlation</span>
<span class="n">corr</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">net_df</span><span class="p">[</span><span class="s2">&quot;Winnings&quot;</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="s2">&quot;Losses&quot;</span><span class="p">])</span>
<span class="n">corr</span> <span class="o">=</span> <span class="s2">&quot;PearsonR: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">((</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">corr</span><span class="p">))))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">5500</span><span class="p">,</span> <span class="o">-</span><span class="mi">18000</span><span class="p">,</span> <span class="n">corr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Naive_Clustering_of_Total_Dataset_12_0.png" src="_images/Naive_Clustering_of_Total_Dataset_12_0.png" />
</div>
</div>
<div class="section" id="linear-relationship">
<h3>Linear Relationship<a class="headerlink" href="#linear-relationship" title="Permalink to this headline">¶</a></h3>
<p>From this graph we can see a <strong>strong negative (Y is inverted) linear relationship</strong> indicating that the more “money” a participant earned in the challenge, the more they lost in general.</p>
<p>This relationship is confirmed with the inclusion of <strong>Pearson Correlation Coefficient</strong>.</p>
<p>Let’s create a histogram representing the total earnings (<strong>Net Win + Net Loss</strong>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s see the range of earnings in our data:</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Minimum: </span><span class="si">{}</span><span class="s2"> Maximum: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">net_df</span><span class="p">[</span><span class="s2">&quot;Final&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s2">&quot;min&quot;</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="s2">&quot;Final&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()[</span><span class="s2">&quot;max&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Minimum: -4250.0 Maximum: 3750.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#The histogram of the data</span>
<span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">net_df</span><span class="p">[</span><span class="s2">&quot;Final&quot;</span><span class="p">],</span> <span class="mi">20</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Earnings&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of Participants&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Histogram of Earnings&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Naive_Clustering_of_Total_Dataset_15_0.png" src="_images/Naive_Clustering_of_Total_Dataset_15_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s learn more about the distribution using a QQPlot</span>
<span class="n">qqplot</span><span class="p">(</span><span class="n">net_df</span><span class="p">[</span><span class="s2">&quot;Final&quot;</span><span class="p">],</span> <span class="n">line</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Naive_Clustering_of_Total_Dataset_16_0.png" src="_images/Naive_Clustering_of_Total_Dataset_16_0.png" />
</div>
</div>
</div>
<div class="section" id="interpretation-of-histogram-and-qqplot">
<h3>Interpretation of Histogram and QQPlot<a class="headerlink" href="#interpretation-of-histogram-and-qqplot" title="Permalink to this headline">¶</a></h3>
<p>The histogram with a total of 20 bins shows us that the distribution of the data somewhat resembles a normal distribution. This is to be expected when working with human-generated data.</p>
<p>However, it is clear that there is data at the two extremeties of the bell curve indicating groups of <strong>outliers</strong>. These outliers are also clearly represented in the QQplot which has tails straying from the centre line.</p>
<p>These groups of outliers are representative of participants which had <strong>total earnings considerably higher or lower</strong> than the average. Later on, we will create a <a class="reference external" href="#box_plot">boxplot representative of participant’s choices</a> with respect to their clusters where we will further discuss the existence of outliers.</p>
</div>
<div class="section" id="clustering">
<h3>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h3>
<p>Visually, it is unclear how many clusters will be most suitable for this graph. We will create a <strong>lineplot</strong> representative of the <strong>total inertia</strong> for each varying quantity of clusters. From this plot, we can interprete the <strong>elbow point</strong> of the line which indicates a suitable number of clusters. Any amount of clusters after this point results in a negligible reduction of inertia and is therefore unnecessary.</p>
<p>This graph will allow us to <strong>visualise the decrease in inertia</strong> between cluster quantities. We can then decide by eye which amount is most suitable. This method is called finding <strong>the elbow-point</strong> of a line curve.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let X equal our points</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">net_df</span><span class="p">[[</span><span class="s2">&quot;Winnings&quot;</span><span class="p">,</span> <span class="s2">&quot;Losses&quot;</span><span class="p">]]</span>

<span class="c1">#List of inertias</span>
<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#Finding and appending Inertia to list</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">30</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1">#Create Inertia Line Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">inertias</span><span class="p">,</span> <span class="s2">&quot;go--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Inertia Reduction&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Clusters&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Inertia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Naive_Clustering_of_Total_Dataset_19_0.png" src="_images/Naive_Clustering_of_Total_Dataset_19_0.png" />
</div>
</div>
<div class="section" id="interpreting-the-inertia-graph">
<h4>Interpreting the Inertia Graph<a class="headerlink" href="#interpreting-the-inertia-graph" title="Permalink to this headline">¶</a></h4>
<p>We can see that the rate of change (or the slope) decreases drastically for more than 10 clusters. Therefore, we can assume that <strong>10 clusters</strong> is a suitable number for this particular graph.</p>
<p>Let’s now continue the process by employing the KMeans algorithm with a cluster allowance of 10. We will then calculate the <strong>label</strong> associated with each data point. This will allow us to seperate the data points on our graph by colour depending on the cluster they belong to. We will also find the <strong>centroids</strong> of each cluster and plot them with a <strong>+</strong> symbol.</p>
</div>
</div>
<div class="section" id="cluster-graph">
<h3>Cluster Graph<a class="headerlink" href="#cluster-graph" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let X equal our points</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">net_df</span><span class="p">[[</span><span class="s2">&quot;Winnings&quot;</span><span class="p">,</span> <span class="s2">&quot;Losses&quot;</span><span class="p">]]</span>

<span class="c1">#Perform kmeans and fit X</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1">#Calculating Labels</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1">#Calculating Centroids</span>
<span class="n">centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>
</pre></div>
</div>
</div>
</div>
<p><a id=cluster_diagram></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>

<span class="c1">#filter rows of original data by label</span>
<span class="n">filtered_label0</span><span class="p">,</span> <span class="n">filtered_label1</span><span class="p">,</span> <span class="n">filtered_label2</span> <span class="o">=</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">filtered_label3</span><span class="p">,</span> <span class="n">filtered_label4</span><span class="p">,</span> <span class="n">filtered_label5</span> <span class="o">=</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">3</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">4</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">filtered_label6</span><span class="p">,</span> <span class="n">filtered_label7</span><span class="p">,</span> <span class="n">filtered_label8</span><span class="p">,</span> <span class="n">filtered_label9</span> <span class="o">=</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">6</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">7</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">8</span><span class="p">],</span> <span class="n">net_df</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">9</span><span class="p">]</span>

<span class="n">filtered_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">filtered_label0</span><span class="p">,</span><span class="n">filtered_label1</span><span class="p">,</span><span class="n">filtered_label2</span><span class="p">,</span><span class="n">filtered_label3</span><span class="p">,</span><span class="n">filtered_label4</span><span class="p">,</span><span class="n">filtered_label5</span>
                  <span class="p">,</span><span class="n">filtered_label6</span><span class="p">,</span><span class="n">filtered_label7</span><span class="p">,</span><span class="n">filtered_label8</span><span class="p">,</span><span class="n">filtered_label9</span><span class="p">]</span>
<span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="s2">&quot;purple&quot;</span><span class="p">,</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="s2">&quot;yellow&quot;</span><span class="p">,</span> <span class="s2">&quot;aqua&quot;</span><span class="p">,</span> <span class="s2">&quot;darkblue&quot;</span><span class="p">,</span> <span class="s2">&quot;brown&quot;</span><span class="p">,</span> <span class="s2">&quot;pink&quot;</span><span class="p">]</span>
<span class="c1">#Inverting y-axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>

<span class="c1">#plotting the clusters</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">filtered_labels</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">filtered_labels</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;Winnings&quot;</span><span class="p">],</span> <span class="n">filtered_labels</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;Losses&quot;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="c1">#Plotting the centroids</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centroids</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">centroids</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>

<span class="c1">#Calculating &amp; placing inertia</span>
<span class="n">inertia</span><span class="o">=</span> <span class="s2">&quot;Inertia: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)))</span>

<span class="c1">#Placing Text</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">5800</span><span class="p">,</span> <span class="o">-</span><span class="mi">18000</span><span class="p">,</span> <span class="n">inertia</span><span class="p">,</span>  <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;top&#39;</span><span class="p">)</span>

<span class="c1">#Axes labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Earnings&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Losses&#39;</span><span class="p">)</span>

<span class="c1">#Plot Title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Net Earnings by Net Loss per Participant&quot;</span><span class="p">)</span>

<span class="c1">#Saving image for reference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;all_clusters&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Naive_Clustering_of_Total_Dataset_24_0.png" src="_images/Naive_Clustering_of_Total_Dataset_24_0.png" />
</div>
</div>
<p><a id=cluster_analysis></a></p>
</div>
<div class="section" id="cluster-graph-analysis">
<h3>Cluster Graph Analysis<a class="headerlink" href="#cluster-graph-analysis" title="Permalink to this headline">¶</a></h3>
<p>In the above graph it is clear that the data does not all come from the same distribution. There are <strong>two very apparent lines</strong>.</p>
<p>We can easily imagine that the more dense line on the left is likely a <strong>combination of data points</strong> from studies allowing participants a total of <strong>95 &amp; 100 tries</strong>. The less dense line further right in the diagram being made up of the remaining participants allowed a total of <strong>150 tries</strong>. This would make sense as more tries would allow users to generally receive more rewards and penalties causing their datapoint to be further to the top right.</p>
<p>As stated previously, the studies employed <strong>various payoff schemes</strong>. This means that harsher penalties and more lucrative rewards were available in some studies but <strong>not in others</strong>. This has an effect on the total amount of profit or loss a participant can make during the game.</p>
<p>We can see that the clusters do a reasonably good job dividing the data. However, some clusters seem less reasonable, particularly the <strong>yellow, blue, and red clusters</strong>.</p>
</div>
</div>
<div class="section" id="comparison-between-opposite-groups">
<h2>Comparison Between Opposite Groups<a class="headerlink" href="#comparison-between-opposite-groups" title="Permalink to this headline">¶</a></h2>
<p>From the above diagram I am interested in viewing the difference between the choices made by users in the <strong>purple cluster</strong> (bottom-left) versus users in the <strong>dark blue</strong> cluster (top-right). We have already segmented our dataset using the <code class="docutils literal notranslate"><span class="pre">filtered_label3</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">filtered_label7</span></code> sets above. We can filter our <code class="docutils literal notranslate"><span class="pre">full_choice</span></code> dataset in a similar fashion.</p>
<p>For simplicity, we will choose <strong>6</strong> participants out of the <strong>57</strong> in the purple group for analysis. We will choose <strong>3 users with the highest profit and 3 users with the lowest profit</strong>.</p>
<p>Clustering participants based on the decks they chose from is a difficult task. Instead, a <strong>time-series chart</strong> may reveal trends in the data more easily. A time-series chart will reveal to us the decision making process of users. We expect to see choices steadily lean towards the <strong>more favourable decks of C and D</strong> in situations where the participant performed well.</p>
<p>As we are viewing the polar extremes of the data, we should expect to see contrasting strategies employed by subjects.</p>
<p><strong>Note: Re-running the cluster algorithm above will cause the clusters to change colour and no longer be associated with the same labels</strong></p>
<div class="section" id="pre-processing">
<h3>Pre-Processing<a class="headerlink" href="#pre-processing" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Filter out top and bottom 3 results</span>
<span class="n">purples</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">filtered_label3</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;Final&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="n">filtered_label3</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;Final&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Here we see the table of top 3 and bottom 3 earners.</span>
<span class="n">purples</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Winnings</th>
      <th>Losses</th>
      <th>Final</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>176</th>
      <td>5950.0</td>
      <td>-5500.0</td>
      <td>450.0</td>
    </tr>
    <tr>
      <th>116</th>
      <td>5750.0</td>
      <td>-5200.0</td>
      <td>550.0</td>
    </tr>
    <tr>
      <th>123</th>
      <td>6050.0</td>
      <td>-5350.0</td>
      <td>700.0</td>
    </tr>
    <tr>
      <th>323</th>
      <td>6570.0</td>
      <td>-3000.0</td>
      <td>3570.0</td>
    </tr>
    <tr>
      <th>526</th>
      <td>7500.0</td>
      <td>-3750.0</td>
      <td>3750.0</td>
    </tr>
    <tr>
      <th>575</th>
      <td>7500.0</td>
      <td>-3750.0</td>
      <td>3750.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s extract the choices of these participants by using their index numbers</span>
<span class="n">purple_choices</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">full_choice</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">purples</span><span class="o">.</span><span class="n">index</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s do the same for the dark blue group. We can use the label 7 already provided to extract the choices as </span>
<span class="c1">#there are only 5 members of the cluster.</span>

<span class="n">blue_choices</span><span class="o">=</span><span class="n">full_choice</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">7</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s see the blue choices table</span>
<span class="n">blue_choices</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Choice_1</th>
      <th>Choice_2</th>
      <th>Choice_3</th>
      <th>Choice_4</th>
      <th>Choice_5</th>
      <th>Choice_6</th>
      <th>Choice_7</th>
      <th>Choice_8</th>
      <th>Choice_9</th>
      <th>Choice_10</th>
      <th>...</th>
      <th>Choice_141</th>
      <th>Choice_142</th>
      <th>Choice_143</th>
      <th>Choice_144</th>
      <th>Choice_145</th>
      <th>Choice_146</th>
      <th>Choice_147</th>
      <th>Choice_148</th>
      <th>Choice_149</th>
      <th>Choice_150</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>532</th>
      <td>4</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>...</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>547</th>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>...</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>549</th>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>...</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>553</th>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>616</th>
      <td>4</td>
      <td>3</td>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>...</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 150 columns</p>
</div></div></div>
</div>
</div>
<div class="section" id="dark-blue-cluster-choice-time-series">
<h3>Dark Blue Cluster Choice Time-Series<a class="headerlink" href="#dark-blue-cluster-choice-time-series" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Creating figure and subplots</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">14</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">blue_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">blue_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#083577&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">blue_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">blue_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#07558d&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">blue_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">blue_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s1">&#39;#0581ab&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">blue_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">blue_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;#02c6d9&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">blue_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">blue_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="s1">&#39;#00feff&#39;</span><span class="p">)</span>

<span class="c1">#Adjusting xticks and yticks</span>
<span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">151</span><span class="p">,</span><span class="n">step</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>

<span class="c1">#Include Final Amount as title to subplot</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">axs</span><span class="p">)):</span>
    <span class="n">fin</span><span class="o">=</span><span class="s2">&quot;Final Amount: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">net_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">blue_choices</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]][</span><span class="s2">&quot;Final&quot;</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">fin</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="c1">#Setting Title</span>
<span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.92</span><span class="p">,</span> <span class="s2">&quot;Dark Blue Cluster Participants Deck Choice over Time&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>

<span class="c1">#Setting axes labels</span>
<span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="s1">&#39;Choice&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;Deck Chosen&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Naive_Clustering_of_Total_Dataset_35_0.png" src="_images/Naive_Clustering_of_Total_Dataset_35_0.png" />
</div>
</div>
<div class="section" id="interpretation-of-dark-blue-participants-choices">
<h4>Interpretation of Dark Blue Participants’ Choices<a class="headerlink" href="#interpretation-of-dark-blue-participants-choices" title="Permalink to this headline">¶</a></h4>
<p>Overall, it is clear that a tendency to choose ‘Deck B’ is a similarity between participants of this cluster. This is particularly evident in the <strong>second</strong> and <strong>fourth</strong> subplots. Both of these users selected ‘Deck B’ for the majority of their choices.</p>
<p>From viewing the remaining 3 time-series charts, we can see that participants <strong>regularly returned to choosing ‘Deck B’</strong> for long periods of time, only <strong>occassionally choosing from a different deck</strong>. We understand that ‘Deck B’ was not considered a favourable deck.</p>
<p>The less-favourable nature of ‘Deck B’ is made more apparent by the fact that the two subplots (2nd, and 4th) choosing ‘Deck B’ the most ended up with the <strong>Greatest Losses</strong> as their final amount.</p>
</div>
</div>
<div class="section" id="purple-cluster-choice-time-series">
<h3>Purple Cluster Choice Time-Series<a class="headerlink" href="#purple-cluster-choice-time-series" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Creating figure and subplots</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">14</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">purple_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">purple_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#a673e3&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">purple_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">purple_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#9669d9&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">purple_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">purple_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s1">&#39;#865ece&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">purple_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">purple_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;#5941b1&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">purple_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">purple_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="s1">&#39;#2d2495&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">purple_choices</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">purple_choices</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="s1">&#39;#040a7c&#39;</span><span class="p">)</span>

<span class="c1">#Adjusting xticks and yticks</span>
<span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">yticklabels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">151</span><span class="p">,</span><span class="n">step</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>

<span class="c1">#Include Final Amount as title to subplot</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">axs</span><span class="p">)):</span>
    <span class="n">fin</span><span class="o">=</span><span class="s2">&quot;Final Amount: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">net_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">purple_choices</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]][</span><span class="s2">&quot;Final&quot;</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">fin</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="c1">#Setting Title</span>
<span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="s2">&quot;Purple Cluster Participants Deck Choice over Time&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>

<span class="c1">#Setting axes labels</span>
<span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="s1">&#39;Choice&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;Deck Chosen&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Naive_Clustering_of_Total_Dataset_38_0.png" src="_images/Naive_Clustering_of_Total_Dataset_38_0.png" />
</div>
</div>
<div class="section" id="interpretation-of-the-purple-participants-choices">
<h4>Interpretation of the Purple Participants’ Choices<a class="headerlink" href="#interpretation-of-the-purple-participants-choices" title="Permalink to this headline">¶</a></h4>
<p>The above 6 time-series charts represent those particpants of the purple cluster with <strong>the highest and lowest</strong> final amount scores. We can see that all users ended the experiment with a positive amount of score. Although some scores are low, they are considerably greater than the scores of the dark blue participants we previously examined. As the lowest earners of the cluster ended with a positive score, we know <strong>the entire cluster of participants ended with a positive score</strong>.</p>
<p>It should be noted that we see <strong>varying time-series lengths</strong> as some participants included here took part in a study involving 95 tries while others had 150. Something we alluded to in the <a class="reference external" href="#cluster_analysis">Cluster Graph Analysis</a> section is that the <strong>number of attempts a subject is allowed can affect their position in the cluster</strong>. Maybe we should account for the fact that participants in the Dark Blue cluster were allowed more attempts and therefore had more opportunity to lose score. In the next notebook, we will re-cluster participants based on their Net Win and Net Loss normalised to their number of attempts.</p>
<p>Visually, we can see these <strong>users favour decks ‘C’ and ‘D’</strong>. We understand these decks to be <strong>favourable</strong> in this experiment. The first 4 subplots from the top visually describe the thought process of the participants. These subjects began by testing each deck but over time favoured ‘C’ and ‘D’.</p>
<p>The remaining 2 subplots exhibit strange choice patterns. Both users selected <strong>only ‘Deck C’</strong> for the duration of the test. This may indicate to us that these particular participants had prior knowledge before beginning the study. However, there is also a possiblity that these are legitimate scores. Maybe this is more indicative of a neurological condition such as OCD.</p>
</div>
</div>
</div>
<div class="section" id="comparison-of-all-clusters">
<h2>Comparison of All Clusters<a class="headerlink" href="#comparison-of-all-clusters" title="Permalink to this headline">¶</a></h2>
<p>In the following section, we will examine some of the differences between the clusters. We will use a <strong>Box and Whisker Plot</strong> to show the general distribution of choices for each cluster. We should expect the boxplot to confirm our analysis above in that;</p>
<ol class="simple">
<li><p>The Dark Blue cluster should be centralised around ‘Deck B’</p></li>
<li><p>The Purple cluster should be centralised around ‘Deck C’</p></li>
</ol>
<p>Analysis of the boxplot will also allow us to see the <strong>spread</strong> of choice amongst the clusters. It is possible that some clusters may have large spreads between their 25% amd 75% quartiles, while others may be more condensed. Maybe there will be a correlation between clusters with a large spread and clusters that seem less natural on the <a class="reference external" href="#cluster_diagram">cluster diagram</a> above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s create a series object representing the average deck chosen per choice for each cluster</span>
<span class="n">darkblue_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">7</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">purple_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">orange_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">red_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">yellow_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">aqua_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">brown_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">8</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pink_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">green_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">blue_avg</span> <span class="o">=</span> <span class="n">full_choice</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1">#let&#39;s combine these objects to create a dataframe of average deck chosen per choice by each cluster.</span>
<span class="n">avg_choices</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">blue_avg</span><span class="p">,</span> <span class="n">red_avg</span><span class="p">,</span> <span class="n">green_avg</span><span class="p">,</span> <span class="n">purple_avg</span><span class="p">,</span> <span class="n">orange_avg</span><span class="p">,</span> <span class="n">yellow_avg</span><span class="p">,</span> <span class="n">aqua_avg</span><span class="p">,</span> <span class="n">darkblue_avg</span><span class="p">,</span> <span class="n">brown_avg</span><span class="p">,</span> <span class="n">pink_avg</span><span class="p">],</span>
            <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Blue&quot;</span><span class="p">,</span> <span class="s2">&quot;Red&quot;</span><span class="p">,</span><span class="s2">&quot;Green&quot;</span><span class="p">,</span><span class="s2">&quot;Purple&quot;</span><span class="p">,</span><span class="s2">&quot;Orange&quot;</span><span class="p">,</span><span class="s2">&quot;Yellow&quot;</span><span class="p">,</span> <span class="s2">&quot;Aqua&quot;</span><span class="p">,</span> <span class="s2">&quot;Dark Blue&quot;</span><span class="p">,</span> <span class="s2">&quot;Brown&quot;</span><span class="p">,</span> <span class="s2">&quot;Pink&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s see the dataframe</span>
<span class="n">avg_choices</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Choice_1</th>
      <th>Choice_2</th>
      <th>Choice_3</th>
      <th>Choice_4</th>
      <th>Choice_5</th>
      <th>Choice_6</th>
      <th>Choice_7</th>
      <th>Choice_8</th>
      <th>Choice_9</th>
      <th>Choice_10</th>
      <th>...</th>
      <th>Choice_141</th>
      <th>Choice_142</th>
      <th>Choice_143</th>
      <th>Choice_144</th>
      <th>Choice_145</th>
      <th>Choice_146</th>
      <th>Choice_147</th>
      <th>Choice_148</th>
      <th>Choice_149</th>
      <th>Choice_150</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Blue</th>
      <td>2.250000</td>
      <td>2.629310</td>
      <td>2.224138</td>
      <td>2.439655</td>
      <td>2.284483</td>
      <td>2.405172</td>
      <td>2.387931</td>
      <td>2.310345</td>
      <td>2.456897</td>
      <td>2.577586</td>
      <td>...</td>
      <td>3.666667</td>
      <td>3.666667</td>
      <td>3.666667</td>
      <td>3.333333</td>
      <td>3.333333</td>
      <td>3.333333</td>
      <td>3.666667</td>
      <td>3.666667</td>
      <td>3.333333</td>
      <td>3.333333</td>
    </tr>
    <tr>
      <th>Red</th>
      <td>2.583333</td>
      <td>2.458333</td>
      <td>2.625000</td>
      <td>2.750000</td>
      <td>2.291667</td>
      <td>2.041667</td>
      <td>2.375000</td>
      <td>2.333333</td>
      <td>2.250000</td>
      <td>2.250000</td>
      <td>...</td>
      <td>2.352941</td>
      <td>2.588235</td>
      <td>2.176471</td>
      <td>2.352941</td>
      <td>2.470588</td>
      <td>3.000000</td>
      <td>2.294118</td>
      <td>2.235294</td>
      <td>2.176471</td>
      <td>1.941176</td>
    </tr>
    <tr>
      <th>Green</th>
      <td>1.924528</td>
      <td>2.320755</td>
      <td>2.377358</td>
      <td>2.094340</td>
      <td>2.226415</td>
      <td>2.264151</td>
      <td>2.056604</td>
      <td>2.301887</td>
      <td>2.283019</td>
      <td>2.245283</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>Purple</th>
      <td>2.192982</td>
      <td>2.157895</td>
      <td>2.456140</td>
      <td>2.473684</td>
      <td>2.175439</td>
      <td>2.368421</td>
      <td>2.543860</td>
      <td>2.631579</td>
      <td>2.561404</td>
      <td>2.701754</td>
      <td>...</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>Orange</th>
      <td>2.076923</td>
      <td>2.461538</td>
      <td>2.401709</td>
      <td>2.495726</td>
      <td>2.205128</td>
      <td>2.299145</td>
      <td>2.418803</td>
      <td>2.384615</td>
      <td>2.478632</td>
      <td>2.401709</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 150 columns</p>
</div></div></div>
</div>
<p><a id=box_plot></a></p>
<div class="section" id="boxplot">
<h3>Boxplot<a class="headerlink" href="#boxplot" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Using .boxplot() gives an annoying warning so we turn warnings off! </span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

<span class="c1">#We use avg_choices.boxplot() as plt.boxplot(avg_choices) refuses to show clusters containing NaN values</span>
<span class="n">avg_choices</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">boxplot</span><span class="p">()</span>

<span class="c1">#Adjusting xticks and yticks</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">),[</span><span class="s2">&quot;Blue&quot;</span><span class="p">,</span> <span class="s2">&quot;Red&quot;</span><span class="p">,</span><span class="s2">&quot;Green&quot;</span><span class="p">,</span><span class="s2">&quot;Purple&quot;</span><span class="p">,</span><span class="s2">&quot;Orange&quot;</span><span class="p">,</span><span class="s2">&quot;Yellow&quot;</span><span class="p">,</span> <span class="s2">&quot;Aqua&quot;</span><span class="p">,</span> <span class="s2">&quot;Dark Blue&quot;</span><span class="p">,</span> <span class="s2">&quot;Brown&quot;</span><span class="p">,</span> <span class="s2">&quot;Pink&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">),[</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1">#Setting Labels and Title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribution of Choices per Cluster&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Cluster&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Deck Choice&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Naive_Clustering_of_Total_Dataset_45_0.png" src="_images/Naive_Clustering_of_Total_Dataset_45_0.png" />
</div>
</div>
<div class="section" id="interpretation-of-the-box-plot">
<h4>Interpretation of the Box Plot<a class="headerlink" href="#interpretation-of-the-box-plot" title="Permalink to this headline">¶</a></h4>
<p><strong>Outliers</strong> in this plot represent a particular choice where the mean of all participants choices is far greater or less than the mean of all the other choices in the game. The existince of outliers could indicate that there is a common point  in which subjects begin to try a different strategy. However, it could also be down to chance.</p>
<p>The <strong>median</strong> and the <strong>spread</strong> tell us more than the outliers here. As expected, the Dark Blue median rests firmly on ‘B’, while the Purple median lies just above ‘C’. The distribution of the Yellow cluster is similar to the Purple cluster. They are also beside each other on the <a class="reference external" href="#cluster_diagram">cluster diagram</a>. This could indicate that performance of these two clusters are similar. The ‘Blue’ cluster has the largest <strong>inter-quartile range</strong>. Its median also rests near ‘C’.</p>
<p>If we consider clusters with medians and ranges residing closer to ‘Deck C’ and ‘Deck D’ in the boxplot as more performant,
it becomes clear that these clusters, namely <strong>Blue</strong>, <strong>Purple</strong>, <strong>Yellow</strong>, and <strong>Brown</strong>, are found closer to the <strong>bottom-left</strong> corner of the <a class="reference external" href="#cluster_diagram">cluster diagram</a>. The remaining clusters are found further towards the <strong>top-right</strong>.</p>
</div>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>This is the end of this Jupyter Notebook. Here we clustered our data by Net Earnings and Net Losses irrespective of study conditions such as <strong>reward scheme</strong> and <strong>number of attempts</strong>. We were able to see a linear relationship in the data which told us that in most cases, as a participant earns more reward, they consequently have more loses. This is related to participants deck choice. Users who favoured Deck ‘B’ such as the dark blue cluster received greater rewards but endured harsher penalties resulting in a net loss over 10 turns. We found that the data closely resembles a <strong>normal distribution</strong> but does contain some <strong>outliers</strong> with large earnings or losses.</p>
<p>From viewing the cluster diagram, we understand that there are <strong>two appararent lines</strong> visible in the graph. This could be indicative of fundamental differences between two portions of the data. This is likely a consequence of different amounts of allowed attempts, as well as different marking schemes. In our next notebook, we will focus on the <strong>cumulative earnings and losses</strong> of participants. This will be a better measure of a participant’s ability to learn from feedback. Following on from that notebook, we will perform a <strong>Federated Learning Approach</strong> on the same data. We will compare the final position of cluster centroids, the total amount of inertia, and the distribution of data points amongst clusters.</p>
</div>
<span id="document-clustering_total_dataset_2"></span><div class="section" id="clustering-of-total-dataset-2-10-intervals">
<h2>Clustering of Total Dataset 2 (10% Intervals)<a class="headerlink" href="#clustering-of-total-dataset-2-10-intervals" title="Permalink to this headline">¶</a></h2>
<p>In the following Notebook, we will be examining and contrasting participants based on their total net income or net loss over the course of the test measured at 10% intervals. That is to say that, for a participant with 100 turns, we will examine their <em>10th</em>, <em>20th</em>, <em>30th</em>, .., and <em>100th</em> round. Clustering participants based on these features will result in a <strong>10-Dimensional space</strong>. We will then perform <em>Principal Component Analysis</em> to understand which of these features are most important. Depending on the results of PCA, we will either perform dimensionality reduction or choose to continue with all 10 features.</p>
<div class="section" id="importing-libraries">
<h3>Importing Libraries<a class="headerlink" href="#importing-libraries" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span><span class="p">,</span> <span class="n">silhouette_samples</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="importing-data">
<h3>Importing Data<a class="headerlink" href="#importing-data" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">full_sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">full_wins_95</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/full_Wins_95.csv&quot;</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_wins_95</span><span class="p">)</span>
<span class="n">full_wins_100</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/full_Wins_100.csv&quot;</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_wins_100</span><span class="p">)</span>
<span class="n">full_wins_150</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/full_Wins_150.csv&quot;</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_wins_150</span><span class="p">)</span>

<span class="n">full_losses_95</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/full_Losses_95.csv&quot;</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_losses_95</span><span class="p">)</span>
<span class="n">full_losses_100</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/full_Losses_100.csv&quot;</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_losses_100</span><span class="p">)</span>
<span class="n">full_losses_150</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/full_Losses_150.csv&quot;</span><span class="p">)</span>
<span class="n">full_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">full_losses_150</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="initial-data-manipulation">
<h3>Initial Data Manipulation<a class="headerlink" href="#initial-data-manipulation" title="Permalink to this headline">¶</a></h3>
<p>From the datasets we previously created, we would like to calculate a participant’s net gain (or loss) at each measured interval for each subject. The calculation is simply  the difference between <strong><code class="docutils literal notranslate"><span class="pre">full_win</span></code> &amp; <code class="docutils literal notranslate"><span class="pre">full_loss</span></code></strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Our Net Datasets</span>
<span class="n">net_sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">net_rolling_95</span><span class="o">=</span><span class="n">full_wins_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">full_losses_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">net_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">net_rolling_95</span><span class="p">)</span>

<span class="n">net_rolling_100</span><span class="o">=</span><span class="p">(</span><span class="n">full_wins_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">full_losses_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">net_rolling</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">~</span>\<span class="n">AppData</span>\<span class="n">Local</span>\<span class="n">Temp</span><span class="o">/</span><span class="n">ipykernel_15228</span><span class="o">/</span><span class="mf">3829859257.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> 
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">net_rolling_100</span><span class="o">=</span><span class="p">(</span><span class="n">full_wins_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">full_losses_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">8</span> <span class="n">net_rolling</span>

<span class="ne">NameError</span>: name &#39;net_rolling&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Our Net Datasets</span>
<span class="n">net_sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">net_rolling_95</span><span class="o">=</span><span class="n">full_wins_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">full_losses_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">net_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">net_rolling_95</span><span class="p">)</span>

<span class="n">net_rolling_100</span><span class="o">=</span><span class="p">(</span><span class="n">full_wins_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">full_losses_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">net_rolling_100</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">net_rolling_100</span><span class="p">,</span> <span class="n">full_wins_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">2</span><span class="p">:]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">net_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">net_rolling_100</span><span class="p">)</span>

<span class="n">net_rolling_150</span><span class="o">=</span><span class="n">full_wins_150</span> <span class="o">+</span> <span class="n">full_losses_150</span><span class="o">.</span><span class="n">values</span>
<span class="n">net_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">net_rolling_150</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Normalising table columns</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">net_sets</span><span class="p">:</span>
    <span class="n">new_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;10%&quot;</span><span class="p">,</span> <span class="s2">&quot;20%&quot;</span><span class="p">,</span> <span class="s2">&quot;30%&quot;</span><span class="p">,</span> <span class="s2">&quot;40%&quot;</span><span class="p">,</span> <span class="s2">&quot;50%&quot;</span><span class="p">,</span><span class="s2">&quot;60%&quot;</span><span class="p">,</span> <span class="s2">&quot;70%&quot;</span><span class="p">,</span> <span class="s2">&quot;80%&quot;</span><span class="p">,</span> <span class="s2">&quot;90%&quot;</span><span class="p">,</span> <span class="s2">&quot;100%&quot;</span><span class="p">]</span>
    <span class="n">s</span><span class="o">.</span><span class="n">set_axis</span><span class="p">(</span><span class="n">new_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let us now combine our datasets</span>
<span class="n">net_set</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">net_sets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="k-means-clustering">
<h2>K-Means Clustering<a class="headerlink" href="#k-means-clustering" title="Permalink to this headline">¶</a></h2>
<p>As is stands, our dataset consists of 10 features. We know that the K-Means algorithm suffers from the ‘curse of dimensionality’. This means that as the dimensions increase, the amount of available space increases exponentially. Eventually, we reach a point where our space is so sparsely populated that K-Means resorts to a 1:1 relationship between number of clusters and number of datapoints.</p>
<p>To avoid this paradigm, we will perform <strong>Principal Component Analysis</strong> (PCA). PCA is used for dimensionality reduction in datasets with many features. On their own, these datasets are difficult to interpret and cannot be plotted on a 2D or 3D plane. PCA aims to increase the interpretability of these datasets. It creates new variables (<strong><em>principal components</em></strong>) that maximize variance. It then solves these variables for their eigenvalues and eigenvectors <span id="id1">[<a class="reference internal" href="intro.html#id16">Jolliffe and Cadima, 2016</a>]</span>.</p>
<div class="section" id="principal-component-analysis">
<h3>Principal Component Analysis<a class="headerlink" href="#principal-component-analysis" title="Permalink to this headline">¶</a></h3>
<p>In order for PCA to work, the data must be standardized. That is to say, all of our features must have a <strong>mean of 0</strong> and a <strong>Standard Deviation of 1</strong>. We will use the <code class="docutils literal notranslate"><span class="pre">preprocessing</span></code> package from <code class="docutils literal notranslate"><span class="pre">sklearnn</span></code> in order to achieve this. Following on from this, we will create as many principal components as there are feature vectors. We will then rank the importance of these principal components by calculating their <strong>eigenvalues</strong>. The comparison of the eigenvalues will allow us to visualise the importance of each. That is, how much variance in the true dataset they are able to account for. We will see this on a <strong>Scree Plot</strong>.</p>
<div class="section" id="standardization">
<h4>Standardization<a class="headerlink" href="#standardization" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Instantiate our scaler</span>
<span class="n">min_max_scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">MinMaxScaler</span><span class="p">()</span>

<span class="c1">#Normalize our dataset</span>
<span class="n">norm_net_set</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">min_max_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">net_set</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">net_set</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="finding-principal-components">
<h4>Finding Principal Components<a class="headerlink" href="#finding-principal-components" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Instantiating our PCA Function</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">svd_solver</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">)</span>

<span class="c1">#Finding the 10 Principal Components of our Datasets</span>
<span class="n">pc_norm_net</span><span class="o">=</span><span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_net_set</span><span class="p">)</span>


<span class="c1">#Creating datasets of the principal components for visualization</span>
<span class="n">pca_df_norm_net_set</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">pc_norm_net</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;PC 1&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 2&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 3&#39;</span><span class="p">,</span>
                                                       <span class="s1">&#39;PC 4&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 5&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 6&#39;</span><span class="p">,</span>
                                                      <span class="s1">&#39;PC 7&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 8&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 9&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 10&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Creating the Scree Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>

<span class="n">PC_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">n_components_</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">PC_values</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span> <span class="s1">&#39;ro-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Scree Plot&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Proportion of Variance Explained&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/clustering_total_dataset_2_16_0.png" src="_images/clustering_total_dataset_2_16_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Proportion of Variance Explained : &quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>  
    
<span class="n">out_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>  
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Cumulative Prop. Variance Explained: &quot;</span><span class="p">,</span> <span class="n">out_sum</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Proportion of Variance Explained :  [0.39471861 0.32002395 0.10276651 0.04771292 0.03652619 0.0323709
 0.02174367 0.02018602 0.0140641  0.00988714]
Cumulative Prop. Variance Explained:  [0.39471861 0.71474256 0.81750906 0.86522198 0.90174817 0.93411907
 0.95586274 0.97604875 0.99011286 1.        ]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="scree-plot-analysis">
<h4>Scree Plot Analysis<a class="headerlink" href="#scree-plot-analysis" title="Permalink to this headline">¶</a></h4>
<p>From the above plot we can see that <strong>71.4%</strong> of the variance in our total dataset is explained by the first and second Principal Components. With this evidence, we can conclude that the first and second Principal Components will suffice for representing the majority (over 70%) of the variance in our data.</p>
</div>
</div>
<div class="section" id="deciding-value-of-k">
<h3>Deciding Value of K<a class="headerlink" href="#deciding-value-of-k" title="Permalink to this headline">¶</a></h3>
<p>We must now decide on a suitable amount of clusters for our algorithm. Two largely used methods for discovering the value of K are: <span class="math notranslate nohighlight">\((a)\)</span> <em>The Elbow Method</em>, and <span class="math notranslate nohighlight">\((b)\)</span> <em>The Silhouette Method</em>.</p>
<div class="section" id="a-the-elbow-method">
<h4><span class="math notranslate nohighlight">\((a)\)</span> The Elbow Method<a class="headerlink" href="#a-the-elbow-method" title="Permalink to this headline">¶</a></h4>
<p>Inelegantly named the <strong>Elbow Method</strong>, it is the oldest method for determining the correct value of K. It is a visual method that focuses on displaying the error cost associated with varying amounts of clusters. The error is known as <strong>the Sum of the Squared Error</strong> (SSE). Visually, the total amount of error will fall at each increment of total number of clusters before reaching a point where it plateaus. This point is known as the elbow point. The loss in error beyond this point is not considerable enough to warrant the use of extra clusters <span id="id2">[<a class="reference internal" href="intro.html#id17">Kodinariya and Makwana, 2013</a>]</span>. The algorithm for calculating the loss function is as follows:</p>
<ul class="simple">
<li><p>where <span class="math notranslate nohighlight">\(k\)</span> is the number of clusters</p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span> is the number of points in cluster <span class="math notranslate nohighlight">\(j\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(c\)</span> is the centroid for cluster <span class="math notranslate nohighlight">\(j\)</span>
$<span class="math notranslate nohighlight">\(SSE = \sum_{j=1}^k\sum_{i=1}^n{(y^{\mathrm{(j)}}_{i} - c_{j})^2}\)</span>$</p></li>
</ul>
<p><strong>Note</strong>: An error I made in the previous notebook was not ‘seeding’ my k-means algorithm. Because of this, on future runs of the same notebook, the algorithm will produce a different output. In the below example, we will use a seed (<code class="docutils literal notranslate"><span class="pre">random_state</span></code>) of 10.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let X equal our points. We use only the first and second Principal Components</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pca_df_norm_net_set</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">]</span>

<span class="c1">#List of inertias</span>
<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#Finding and appending Inertia to list</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1">#Create Inertia Line Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">inertias</span><span class="p">,</span> <span class="s2">&quot;go--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Inertia Reduction&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Clusters&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Inertia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/clustering_total_dataset_2_20_0.png" src="_images/clustering_total_dataset_2_20_0.png" />
</div>
</div>
<p>From the above graph, it is difficult to understand whether or not 3 or 4 clusters would be considered the better option. Let’s do a cross examination using our next method for determining k.</p>
</div>
<div class="section" id="b-the-silhouette-method">
<h4><span class="math notranslate nohighlight">\((b)\)</span> The Silhouette Method<a class="headerlink" href="#b-the-silhouette-method" title="Permalink to this headline">¶</a></h4>
<p>The Silhouette method is also used to determine the best value for K. This method measures the similarity of each point to its own cluster versus every other cluster. The method provides a <strong>succinct graphical representation</strong> describing how well each data point <span class="math notranslate nohighlight">\((i)\)</span> is described.
The steps to find the Silhouette Score of data point <span class="math notranslate nohighlight">\(i\)</span> are as follows:</p>
<ul class="simple">
<li><p>Compute <span class="math notranslate nohighlight">\(a_{i}\)</span>: The average distance of that point with all other points in the same cluster.</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(b_{i}\)</span>: The average distance of that point with all the points in the closest cluster to its cluster.</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(S_{i}\)</span> — silhouette coefficient or i’th point using below mentioned formula.</p></li>
</ul>
<p>The formula is as follows: $<span class="math notranslate nohighlight">\(S_{i} = \frac{b_{i} - a_{i}}{\max{(b_{i}, a_{i})}}\)</span>$</p>
<p>Once you obtain all of the <strong>Silhouette Coefficients</strong> (all <span class="math notranslate nohighlight">\(S_{i}\)</span>), you find the average to achieve the silhouette score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Defining the range of clusters</span>
<span class="n">range_n_clusters</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>

<span class="c1">#Letting PC1 &amp; PC2 = X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pca_df_norm_net_set</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>

<span class="c1">#Defining subplots</span>
<span class="k">for</span> <span class="n">n_clusters</span> <span class="ow">in</span> <span class="n">range_n_clusters</span><span class="p">:</span>
    <span class="c1"># Create a subplot with 1 row and 2 columns</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
    
    <span class="c1">#Setting x-axis lim</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="c1">#Creating spacing on y-lim</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_clusters</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span><span class="p">])</span>

    <span class="c1">#initialising clusters</span>
    <span class="n">clusterer</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">clusterer</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="c1"># The silhouette_score gives the average value for all the samples.</span>
    <span class="c1"># This gives a perspective into the density and separation of the formed</span>
    <span class="c1"># clusters</span>
    <span class="n">silhouette_avg</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;For n_clusters =&quot;</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span>
          <span class="s2">&quot;The average silhouette_score is :&quot;</span><span class="p">,</span> <span class="n">silhouette_avg</span><span class="p">)</span>

    <span class="c1"># Compute the silhouette scores for each sample</span>
    <span class="n">sample_silhouette_values</span> <span class="o">=</span> <span class="n">silhouette_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">)</span>

    <span class="n">y_lower</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
        <span class="c1"># Aggregate the silhouette scores for samples belonging to</span>
        <span class="c1"># cluster i, and sort them</span>
        <span class="n">ith_cluster_silhouette_values</span> <span class="o">=</span> \
            <span class="n">sample_silhouette_values</span><span class="p">[</span><span class="n">cluster_labels</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>

        <span class="n">ith_cluster_silhouette_values</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

        <span class="n">size_cluster_i</span> <span class="o">=</span> <span class="n">ith_cluster_silhouette_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y_upper</span> <span class="o">=</span> <span class="n">y_lower</span> <span class="o">+</span> <span class="n">size_cluster_i</span>

        <span class="n">color</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">nipy_spectral</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_clusters</span><span class="p">)</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">fill_betweenx</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_lower</span><span class="p">,</span> <span class="n">y_upper</span><span class="p">),</span>
                          <span class="mi">0</span><span class="p">,</span> <span class="n">ith_cluster_silhouette_values</span><span class="p">,</span>
                          <span class="n">facecolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

        <span class="c1"># Label the silhouette plots with their cluster numbers at the middle</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">y_lower</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">size_cluster_i</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

        <span class="c1"># Compute the new y_lower for next plot</span>
        <span class="n">y_lower</span> <span class="o">=</span> <span class="n">y_upper</span> <span class="o">+</span> <span class="mi">10</span>  <span class="c1"># 10 for the 0 samples</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;The silhouette plot for the various clusters.&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;The silhouette coefficient values&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Cluster label&quot;</span><span class="p">)</span>

    <span class="c1"># The vertical line for average silhouette score of all the values</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">silhouette_avg</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>  <span class="c1"># Clear the yaxis labels / ticks</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="c1"># 2nd Plot showing the actual clusters formed</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">nipy_spectral</span><span class="p">(</span><span class="n">cluster_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_clusters</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

    <span class="c1"># Labeling the clusters</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="n">clusterer</span><span class="o">.</span><span class="n">cluster_centers_</span>
    <span class="c1"># Draw white circles at cluster centers</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centers</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centers</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centers</span><span class="p">):</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;$</span><span class="si">%d</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;The visualization of the clustered data.&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature space for the 1st Principal Component&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Feature space for the 2nd Principal Component&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">((</span><span class="s2">&quot;Silhouette analysis for KMeans clustering on sample data &quot;</span>
                  <span class="s2">&quot;with n_clusters = </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">n_clusters</span><span class="p">),</span>
                 <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>For n_clusters = 2 The average silhouette_score is : 0.3540661377361447
For n_clusters = 3 The average silhouette_score is : 0.3899300210703239
For n_clusters = 4 The average silhouette_score is : 0.3901970654091925
For n_clusters = 5 The average silhouette_score is : 0.34447383123098063
</pre></div>
</div>
<img alt="_images/clustering_total_dataset_2_23_1.png" src="_images/clustering_total_dataset_2_23_1.png" />
<img alt="_images/clustering_total_dataset_2_23_2.png" src="_images/clustering_total_dataset_2_23_2.png" />
<img alt="_images/clustering_total_dataset_2_23_3.png" src="_images/clustering_total_dataset_2_23_3.png" />
<img alt="_images/clustering_total_dataset_2_23_4.png" src="_images/clustering_total_dataset_2_23_4.png" />
</div>
</div>
<p>The silhouette scores displayed above finalise our decision that 4 clusters is the most suitable amount. Although, it should be noted that there is very slight increase in score between 3 and 4 clusters. This is likely due to the data distribution. From the visualizations on the right, it is clear that this data is evenly distributed. Visually, it is difficult to seperate clusters by eye. This is to be expected as this dataset is supposed to represent “<em>a super control set</em>”. The inclusion of extra data (possibly of participants with cognitive disorders) would have allowed for more suitable clustering.</p>
</div>
</div>
<div class="section" id="clustering">
<h3>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h3>
<p>We will now reproduce our K-Means clustering algorithm with <span class="math notranslate nohighlight">\(K = 4\)</span> . Again, for reproducability, we will seed our algorithm with the value 10. In order to analyse the clusters, we will colour each data point depending on the study it is part of. This will allow us to understand if there is a relation between clusters chosen vs origin of the data. We will use the <code class="docutils literal notranslate"><span class="pre">seaborn.sns</span></code> scatterplot package for this visualization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let&#39;s append our studies to the data</span>

<span class="n">studies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">full_wins_95</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span><span class="n">full_wins_100</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span><span class="n">full_wins_150</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">:]])</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">pc1_pc2_with_studies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pca_df_norm_net_set</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">studies</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">)</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">pc1_pc2_with_studies</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">pc1_pc2_with_studies</span><span class="p">[</span><span class="s2">&quot;Cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

<span class="c1">#Printing inertia</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The total inertia (SSE) is: </span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#Setting titles</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Visualising Spread of Individual Studies&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Visualising Clusters&quot;</span><span class="p">)</span>

<span class="c1">#Plotting points</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;PC 1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;PC 2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">pc1_pc2_with_studies</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Study&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;PC 1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;PC 2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">pc1_pc2_with_studies</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Cluster&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1">#Setting centroids for cluster graph</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">centers</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;.05&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The total inertia (SSE) is: 43.04
</pre></div>
</div>
<img alt="_images/clustering_total_dataset_2_27_1.png" src="_images/clustering_total_dataset_2_27_1.png" />
</div>
</div>
<div class="section" id="cluster-analysis">
<h4>Cluster Analysis<a class="headerlink" href="#cluster-analysis" title="Permalink to this headline">¶</a></h4>
<p>It is interesting to see that visually, there seems to be more data points from particular studies included in certain clusters. For example, viewing cluster 1, we can see that the majority of the datapoints consist of subjects from the <span id="id3">[<a class="reference internal" href="intro.html#id12">Wood <em>et al.</em>, 2005</a>]</span> study. Again, it would have been ideal to be able to compare these graphs with the inclusion of participants outside of the control group. Unfortunately, due to time constraints, I will not be performing this research as part of this assignment.</p>
<p>However, something we can do instead is measure the proportions of each cluster made up of the studies. Perhaps we will prove that cluster 1 is infact majorly consisting of participants from the <span id="id4">[<a class="reference internal" href="intro.html#id12">Wood <em>et al.</em>, 2005</a>]</span> study. In our next notebook we will before a <strong>Federated Learning</strong> approach on the same data. We can conclude by comparing the proprtions of the clusters. As the data is a control group with even distribution, possibly a federated approach will result in the data points being more evenly spread amongst clusters. We will also compare the SSE of the two methods.</p>
<p>To do this, we must convert our Study column values into numerical values. This is called <strong>Encoding</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Instantiate the Encoder</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>

<span class="c1">#Fit it to our Study </span>
<span class="n">le</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">pc1_pc2_with_studies</span><span class="o">.</span><span class="n">Study</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>

<span class="c1">#Create a Count column for summation</span>
<span class="n">pc1_pc2_with_studies</span><span class="p">[</span><span class="s2">&quot;Count&quot;</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pc1_pc2_with_studies</span><span class="p">[[</span><span class="s2">&quot;Cluster&quot;</span><span class="p">,</span> <span class="s2">&quot;Study&quot;</span><span class="p">,</span> <span class="s2">&quot;Count&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;Study&quot;</span><span class="p">,</span> <span class="s2">&quot;Cluster&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Count</th>
    </tr>
    <tr>
      <th>Study</th>
      <th>Cluster</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">Fridberg</th>
      <th>1</th>
      <td>12</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">Horstmann</th>
      <th>1</th>
      <td>27</td>
    </tr>
    <tr>
      <th>2</th>
      <td>86</td>
    </tr>
    <tr>
      <th>3</th>
      <td>14</td>
    </tr>
    <tr>
      <th>4</th>
      <td>35</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">Kjome</th>
      <th>1</th>
      <td>14</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">Maia</th>
      <th>1</th>
      <td>24</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">Premkumar</th>
      <th>1</th>
      <td>12</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">Steingroever2011</th>
      <th>1</th>
      <td>8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>24</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9</td>
    </tr>
    <tr>
      <th>4</th>
      <td>16</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">SteingroverInPrep</th>
      <th>1</th>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>35</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>21</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">Wetzels</th>
      <th>1</th>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>24</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">Wood</th>
      <th>1</th>
      <td>110</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>25</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">Worthy</th>
      <th>1</th>
      <td>25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see from the above table that Cluster 1 does infact contain a large amount of subjects from the <span id="id5">[<a class="reference internal" href="intro.html#id12">Wood <em>et al.</em>, 2005</a>]</span>. In a similar fashion, cluster 2 holds a majority of the <span id="id6">[<a class="reference internal" href="intro.html#id5">Horstmann <em>et al.</em>, 2012</a>]</span> data points. It will be interesting to see if the Federated approach yields different results.</p>
</div>
</div>
</div>
<span id="document-federated_clustering"></span><div class="section" id="federated-clustering-approach-10-intervals">
<h2>Federated Clustering Approach (10% Intervals)<a class="headerlink" href="#federated-clustering-approach-10-intervals" title="Permalink to this headline">¶</a></h2>
<p>In the following Notebook, we will be performing K-Means clustering as previous, except we will be employing a <strong>Federated Learning</strong> approach. That is to say, we will be treating the data collected from different studies as private and siloed instances that cannot be shared. <em>Federated Learning</em> is a deep learning approach pioneered by Google that focuses on retaining the privacy of sensitive data. We will treat the individual studies as independent silos of data.</p>
<p>For each study, we will <strong>assume</strong> that principal components 1 and 2 are sufficient for representing a majority of the variance within the data. This assumption arises as we require all data to exist within the same <span class="math notranslate nohighlight">\(n\)</span>-dimensional plane (in our case <span class="math notranslate nohighlight">\(n = 2\)</span>). We will employ the Elbow Method once more for each survey. Visual analysis of the graphs will allow us to better understand the correct value for k in each instance. We will run our K-Means algorithm for each server.</p>
<p>From then, we will collect all of the cluster centroids in a common array. It is at this point that the data will no longer be siloed. Although it is important to preserve the privacy of the data, the location of the centroids is considered a property of the machine learning model we are using. In most Federated Learning cases, returning attributes or properties of the model is standard practice, so long as it does not risk the security of the sensitive data. In this particular example, it is not possible to infer the values associated with specific data points from the centroids. Therefore, the privacy of the data has not been breached.</p>
<p>Using the centroids, we will once again use the Elbow Point of an inertia reduction diagram to calculate a good value for k. We will perform a second iteration of the K-Means algorithm using our new value for k on the centroids. Once complete, we will use this new information to combine clusters of the original siloed data and return the results. We will compare this with our clusters from the previous notebook.</p>
</div>
<div class="section" id="packages">
<h2>Packages<a class="headerlink" href="#packages" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-loading">
<h2>Data Loading<a class="headerlink" href="#data-loading" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#Fridberg</span>
<span class="n">fridberg_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Fridberg_rolling_Wins_95.csv&quot;</span><span class="p">)</span>
<span class="n">fridberg_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Fridberg_rolling_Losses_95.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">fridberg_win</span><span class="p">,</span> <span class="n">fridberg_loss</span><span class="p">])</span>

<span class="c1">#Horstmann</span>
<span class="n">horstmann_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Horstmann_rolling_Wins_100.csv&quot;</span><span class="p">)</span>
<span class="n">horstmann_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Horstmann_rolling_Losses_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">horstmann_win</span><span class="p">,</span> <span class="n">horstmann_loss</span><span class="p">])</span>

<span class="c1">#Kjome</span>
<span class="n">kjome_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Kjome_rolling_Wins_100.csv&quot;</span><span class="p">)</span>
<span class="n">kjome_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Kjome_rolling_Losses_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">kjome_win</span><span class="p">,</span> <span class="n">kjome_loss</span><span class="p">])</span>

<span class="c1">#Maia</span>
<span class="n">maia_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Maia_rolling_Wins_100.csv&quot;</span><span class="p">)</span>
<span class="n">maia_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Maia_rolling_Losses_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">maia_win</span><span class="p">,</span> <span class="n">maia_loss</span><span class="p">])</span>

<span class="c1">#Premkumar</span>
<span class="n">premkumar_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Premkumar_rolling_Wins_100.csv&quot;</span><span class="p">)</span>
<span class="n">premkumar_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Premkumar_rolling_Losses_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">premkumar_win</span><span class="p">,</span> <span class="n">premkumar_loss</span><span class="p">])</span>

<span class="c1">#Steingrover150</span>
<span class="n">steingrover100_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Steingroever2011_rolling_Wins_150.csv&quot;</span><span class="p">)</span>
<span class="n">steingrover100_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Steingroever2011_rolling_Losses_150.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">steingrover100_win</span><span class="p">,</span> <span class="n">steingrover100_loss</span><span class="p">])</span>

<span class="c1">#Steingrover100</span>
<span class="n">steingrover150_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/SteingroverInPrep_rolling_Wins_100.csv&quot;</span><span class="p">)</span>
<span class="n">steingrover150_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/SteingroverInPrep_rolling_Losses_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">steingrover150_win</span><span class="p">,</span> <span class="n">steingrover150_loss</span><span class="p">])</span>

<span class="c1">#Wetzels</span>
<span class="n">wetzels_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Wetzels_rolling_Wins_150.csv&quot;</span><span class="p">)</span>
<span class="n">wetzels_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Wetzels_rolling_Losses_150.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">wetzels_win</span><span class="p">,</span> <span class="n">wetzels_loss</span><span class="p">])</span>

<span class="c1">#Wood</span>
<span class="n">wood_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Wood_rolling_Wins_100.csv&quot;</span><span class="p">)</span>
<span class="n">wood_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Wood_rolling_Losses_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">wood_win</span><span class="p">,</span> <span class="n">wood_loss</span><span class="p">])</span>

<span class="c1">#Worthy</span>
<span class="n">worthy_win</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Worthy_rolling_Wins_100.csv&quot;</span><span class="p">)</span>
<span class="n">worthy_loss</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/cleaned/Worthy_rolling_Losses_100.csv&quot;</span><span class="p">)</span>
<span class="n">sets</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">worthy_win</span><span class="p">,</span> <span class="n">worthy_loss</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="data-manipulation">
<h3>Data Manipulation<a class="headerlink" href="#data-manipulation" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#We find the net score for each participant of each study as before.</span>
<span class="n">net_sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sets</span><span class="p">:</span>
    <span class="n">st</span><span class="o">=</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">net_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">st</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>At this point, we have created a dataset for each study accounting for participants’ net cummulative score measured at 10% intervals.</p>
</div>
</div>
<div class="section" id="k-means-clustering">
<h2>K-Means Clustering<a class="headerlink" href="#k-means-clustering" title="Permalink to this headline">¶</a></h2>
<div class="section" id="standardization">
<h3>Standardization<a class="headerlink" href="#standardization" title="Permalink to this headline">¶</a></h3>
<p>As before, we must standardize our data so that each feature has a <strong>mean of 0</strong> and a <strong>standard deviation of 1</strong>. We will not be using a scree plot to find the cumulative variance represented by the principal components as we assume 2 principal components is sufficient.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Instantiate our scaler</span>
<span class="n">min_max_scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">MinMaxScaler</span><span class="p">()</span>

<span class="c1">#normalized set</span>
<span class="n">norm_sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#Normalize our datasets</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">net_sets</span><span class="p">:</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">min_max_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">s</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">norm_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="perfoming-pca">
<h3>Perfoming PCA<a class="headerlink" href="#perfoming-pca" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pca_sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#Instantiating our PCA Function</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">svd_solver</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">)</span>

<span class="c1">#Finding the 10 Principal Components of our Dataset</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">norm_sets</span><span class="p">:</span>
    <span class="n">pc_norm_set</span><span class="o">=</span><span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

    <span class="c1">#Creating datasets of the principal components for visualization</span>
    <span class="n">pc_norm_set</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">pc_norm_set</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;PC 1&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 2&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 3&#39;</span><span class="p">,</span>
                                                       <span class="s1">&#39;PC 4&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 5&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 6&#39;</span><span class="p">,</span>
                                                      <span class="s1">&#39;PC 7&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 8&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 9&#39;</span><span class="p">,</span> <span class="s1">&#39;PC 10&#39;</span><span class="p">])</span>
    <span class="n">pca_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pc_norm_set</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Attaching survey names</span>
<span class="n">finished_sets</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">pca_sets</span><span class="p">):</span>
    <span class="n">st</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">pca_sets</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">2</span><span class="p">:]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">finished_sets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">st</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">+=</span><span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="the-elbow-method">
<h3>The Elbow Method<a class="headerlink" href="#the-elbow-method" title="Permalink to this headline">¶</a></h3>
<p>We will now perform the elbow method for each of our servers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Setting up subplots</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">finished_sets</span><span class="p">:</span>
    <span class="c1">#Let X equal our points. We use only the first and second Principal Components</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1">#List of inertias</span>
    <span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1">#Finding and appending Inertia to list</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

    <span class="c1">#Create Inertia Line Plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">inertias</span><span class="p">,</span> <span class="s2">&quot;go--&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Inertia Reduction of </span><span class="si">{</span><span class="n">s</span><span class="o">.</span><span class="n">Study</span><span class="o">.</span><span class="n">unique</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Clusters&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Inertia&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/federated_clustering_15_0.png" src="_images/federated_clustering_15_0.png" />
<img alt="_images/federated_clustering_15_1.png" src="_images/federated_clustering_15_1.png" />
<img alt="_images/federated_clustering_15_2.png" src="_images/federated_clustering_15_2.png" />
<img alt="_images/federated_clustering_15_3.png" src="_images/federated_clustering_15_3.png" />
<img alt="_images/federated_clustering_15_4.png" src="_images/federated_clustering_15_4.png" />
<img alt="_images/federated_clustering_15_5.png" src="_images/federated_clustering_15_5.png" />
<img alt="_images/federated_clustering_15_6.png" src="_images/federated_clustering_15_6.png" />
<img alt="_images/federated_clustering_15_7.png" src="_images/federated_clustering_15_7.png" />
<img alt="_images/federated_clustering_15_8.png" src="_images/federated_clustering_15_8.png" />
<img alt="_images/federated_clustering_15_9.png" src="_images/federated_clustering_15_9.png" />
</div>
</div>
<p>It is difficult to choose a k in some cases from the plots above. We will list the studies and the number of clusters they will use as key-value pairs below:</p>
<ul class="simple">
<li><p>Fridberg 3</p></li>
<li><p>Hortsmann 3</p></li>
<li><p>Kjome 4</p></li>
<li><p>Maia 4</p></li>
<li><p>Premkumar 3</p></li>
<li><p>Steingrover2011 3</p></li>
<li><p>SteingroverInPrep 3</p></li>
<li><p>Wetzels 3</p></li>
<li><p>Wood 3</p></li>
<li><p>Worthy 3</p></li>
</ul>
<p>Giving us a total of <strong>32</strong> clusters across 10 studies. Let’s perform our K-Means algorithm.</p>
</div>
<div class="section" id="id1">
<h3>K-Means Clustering<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">)</span>

<span class="n">cluster_order</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">centroids</span><span class="o">=</span><span class="p">[],</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">positions</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>
             
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">30</span><span class="p">))</span>

<span class="c1">#Paramater i accesses the cluster_order list and the positions list</span>
<span class="n">i</span> <span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">study</span> <span class="ow">in</span> <span class="n">finished_sets</span><span class="p">:</span>
    
    <span class="n">X</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">]</span>
    
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">cluster_order</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="c1">#Calculating Labels</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
    <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    
    <span class="c1">#Adding labels to our study dataframes</span>
    <span class="n">study</span><span class="p">[</span><span class="s2">&quot;Cluster&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">label</span>

    <span class="c1">#Calculating Centroids</span>
    <span class="n">centroid</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Centroid PC 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Centroid PC 2&quot;</span><span class="p">])</span>
    <span class="n">centroid</span><span class="p">[</span><span class="s2">&quot;Study&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">study</span><span class="o">.</span><span class="n">Study</span><span class="o">.</span><span class="n">unique</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">centroids</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">centroids</span><span class="p">,</span> <span class="n">centroid</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1">#Associating points with centroid</span>
    <span class="n">study</span><span class="p">[</span><span class="s2">&quot;Centroid X&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">centroid</span><span class="o">.</span><span class="n">loc</span>
    
    <span class="k">for</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
        
        <span class="c1">#Plotting data</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;PC 1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;PC 2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">][</span><span class="n">label</span><span class="o">==</span><span class="n">lbl</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]])</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Clustering of </span><span class="si">{</span><span class="n">study</span><span class="o">.</span><span class="n">Study</span><span class="o">.</span><span class="n">unique</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1">#Plotting centroids</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Centroid PC 1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Centroid PC 2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">centroid</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">positions</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;.05&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">i</span><span class="o">+=</span><span class="mi">1</span>

<span class="c1">#Fixing centroid index</span>
<span class="n">centroids</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">~</span>\<span class="n">AppData</span>\<span class="n">Local</span>\<span class="n">Temp</span><span class="o">/</span><span class="n">ipykernel_16672</span><span class="o">/</span><span class="mf">2759545651.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">cluster_order</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">labels</span><span class="p">,</span> <span class="n">centroids</span><span class="o">=</span><span class="p">[],</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;seaborn&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="centroid-elbow-method">
<h3>Centroid Elbow Method<a class="headerlink" href="#centroid-elbow-method" title="Permalink to this headline">¶</a></h3>
<p>We now have a collection of all centroids for all seperate studies. Let’s plot these, once again perform inertia reduction and select <span class="math notranslate nohighlight">\(k\)</span> using the elbow method, and finally cluster our centroids.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Centroid PC 1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Centroid PC 2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">centroids</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Study&quot;</span><span class="p">,</span>
                   <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Centroid Locations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/federated_clustering_20_0.png" src="_images/federated_clustering_20_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Let X equal our points. We use only the first and second Principal Components</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">centroids</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">]</span>

<span class="c1">#List of inertias</span>
<span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#Finding and appending Inertia to list</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1">#Create Inertia Line Plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">inertias</span><span class="p">,</span> <span class="s2">&quot;go--&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Inertia Reduction of Centroid Clusters&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Clusters&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Inertia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/federated_clustering_21_0.png" src="_images/federated_clustering_21_0.png" />
</div>
</div>
<p>From the above plot it seems that 3 will be an acceptable value for <span class="math notranslate nohighlight">\(k\)</span>. Let’s perform the clustering and better understand which centroids belong together.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Clustering of Centroids&quot;</span><span class="p">)</span>

<span class="c1">#Let X equal our points</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">centroids</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">]</span>

<span class="c1">#Perform kmeans and fit X</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1">#Calculating Labels</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1">#Calculating centroids</span>
<span class="n">centroid_centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>

<span class="k">for</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
        
        <span class="c1">#Plotting data</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Centroid PC 1&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Centroid PC 2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">label</span><span class="o">==</span><span class="n">lbl</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1">#Concat the label to our centroid df</span>
<span class="n">centroids</span><span class="p">[</span><span class="s2">&quot;Cluster&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">label</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/federated_clustering_23_0.png" src="_images/federated_clustering_23_0.png" />
</div>
</div>
</div>
<div class="section" id="visualization-of-federated-result">
<h3>Visualization of Federated Result<a class="headerlink" href="#visualization-of-federated-result" title="Permalink to this headline">¶</a></h3>
<p>At this point, we will conglomerate all of the data points into one graph. We will instantiate the kmeans algorithm with 3 centroids which we calculated for our cluster centers above. Note that although the data will be represented on one plot, they still remain siloed.</p>
<p><strong>Note: Currently Struggling with the particular visualization. It is difficult to reverse-engineer clusters of clusters to associate them with the original points. Currently looking into it. Since I’m 4 days behind I thought it would be best to upload the book in its current state and fix this issue when I am able to.</strong></p>
</div>
</div>
<span id="document-conclusion"></span><div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>In this Jupyter boook, we investigated employing the K-Means clustering algorithm on a dataset consisting of the results of 617 healthy participants on the <strong>Iowa Gambling Task</strong>. We performed our investigation under the hypothesis that participant’s show little to no irregularities in the data because of their healthy nature. This dataset serves as a <em>super control group</em> that can be used to quantify the the ability of other participants who may be suffering from neurological conditions, whether they be hereditary or self-inflicted from substance abuse. There are various studies <span id="id1">[<a class="reference internal" href="intro.html#id4">Fridberg <em>et al.</em>, 2010</a>, <a class="reference internal" href="intro.html#id5">Horstmann <em>et al.</em>, 2012</a>, <a class="reference internal" href="intro.html#id6">Kjome <em>et al.</em>, 2010</a>, <a class="reference internal" href="intro.html#id3">Steingroever <em>et al.</em>, 2015</a>]</span> that have already made use of this dataset as a control. For that reason, it is important to verify the integrity of this data.</p>
<p>In this book, we were able to:</p>
<ol class="simple">
<li><p>Perform data cleaning and data wrangling tasks to ensure that results from different studies were siloed and were not aggregated together. In order to infer conclusions from the data, it is paramount that our features are rich in information. We performed feature engineering on our data to allow us to measure a participant’s progress throughout the game, as well as their ability to learn from the feedback they received at every round.</p></li>
<li><p>In our analysis, we were able to confirm the hypothesis that participants partaking in any of the individual surveys were able to meet the expectations set for a typical healthy person performing the IGT.</p></li>
<li><p>We performed a federated learning approach to clustering which saw us achieve different end clusters to the centralised approach.</p></li>
</ol>
<div class="section" id="future-work">
<h3>Future Work<a class="headerlink" href="#future-work" title="Permalink to this headline">¶</a></h3>
<p>Currently, there are many contradicting studies regarding the performance of substance abusers and participants with neurological dissabilities on the IGT. Our particular study would greatly benefit from the inclusion of users who fall into one of the aforementioned sub-groups. We would expect that the K-Means algorithm would perform well when clustering unhealthy vs healthy participants. Lastly, we would like the study the impact of different playing conditions (number of turns and payoff scheme used) on participant’s likelihood to make good choices and retain sensitivity to long term effects.</p>
</div>
</div>
<span id="document-bibliography"></span><div class="section" id="bibliography">
<h2>Bibliography<a class="headerlink" href="#bibliography" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p id="id1"><dl class="citation">
<dt class="label" id="id3"><span class="brackets">FQA+10</span></dt>
<dd><p>Daniel J. Fridberg, Sarah Queller, Woo-Young Ahn, Woojae Kim, Anthony J. Bishara, Jerome R. Busemeyer, Linda Porrino, and Julie C. Stout. Cognitive mechanisms underlying risky decision-making in chronic cannabis users. <em>Journal of Mathematical Psychology</em>, 54(1):28–38, 2010. Contributions of Mathematical Psychology to Clinical Science and Assessment. URL: <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0022249609001205">https://www.sciencedirect.com/science/article/pii/S0022249609001205</a>, <a class="reference external" href="https://doi.org/https://doi.org/10.1016/j.jmp.2009.10.002">doi:https://doi.org/10.1016/j.jmp.2009.10.002</a>.</p>
</dd>
<dt class="label" id="id4"><span class="brackets">HVN12</span></dt>
<dd><p>Annette Horstmann, Arno Villringer, and Jane Neumann. Iowa gambling task: there is more to consider than long-term outcome. using a linear equation model to disentangle the impact of outcome and frequency of gains and losses. <em>Frontiers in Neuroscience</em>, 6:61, 2012. URL: <a class="reference external" href="https://www.frontiersin.org/article/10.3389/fnins.2012.00061">https://www.frontiersin.org/article/10.3389/fnins.2012.00061</a>, <a class="reference external" href="https://doi.org/10.3389/fnins.2012.00061">doi:10.3389/fnins.2012.00061</a>.</p>
</dd>
<dt class="label" id="id15"><span class="brackets">JC16</span></dt>
<dd><p>Ian T. Jolliffe and Jorge Cadima. Principal component analysis: a review and recent developments. <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em>, 374(2065):20150202, 2016. URL: <a class="reference external" href="https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2015.0202">https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2015.0202</a>, <a class="reference external" href="https://arxiv.org/abs/https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2015.0202">arXiv:https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2015.0202</a>, <a class="reference external" href="https://doi.org/10.1098/rsta.2015.0202">doi:10.1098/rsta.2015.0202</a>.</p>
</dd>
<dt class="label" id="id5"><span class="brackets">KLS+10</span></dt>
<dd><p>Kimberly L. Kjome, Scott D. Lane, Joy M. Schmitz, Charles Green, Liangsuo Ma, Irshad Prasla, Alan C. Swann, and F. Gerard Moeller. Relationship between impulsivity and decision making in cocaine dependence. <em>Psychiatry Research</em>, 178(2):299–304, 2010. URL: <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0165178109004405">https://www.sciencedirect.com/science/article/pii/S0165178109004405</a>, <a class="reference external" href="https://doi.org/https://doi.org/10.1016/j.psychres.2009.11.024">doi:https://doi.org/10.1016/j.psychres.2009.11.024</a>.</p>
</dd>
<dt class="label" id="id16"><span class="brackets">KM13</span></dt>
<dd><p>Trupti Kodinariya and Prashant Makwana. Review on determining of cluster in k-means clustering. <em>International Journal of Advance Research in Computer Science and Management Studies</em>, 1:90–95, 01 2013.</p>
</dd>
<dt class="label" id="id13"><span class="brackets">LSTS20</span></dt>
<dd><p>Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: challenges, methods, and future directions. <em>IEEE Signal Processing Magazine</em>, 37(3):50–60, 2020. <a class="reference external" href="https://doi.org/10.1109/MSP.2020.2975749">doi:10.1109/MSP.2020.2975749</a>.</p>
</dd>
<dt class="label" id="id6"><span class="brackets">MM04</span></dt>
<dd><p>Tiago V. Maia and James L. McClelland. A reexamination of the evidence for the somatic marker hypothesis: what participants really know in the iowa gambling task. <em>Proceedings of the National Academy of Sciences</em>, 101(45):16075–16080, 2004. URL: <a class="reference external" href="https://www.pnas.org/content/101/45/16075">https://www.pnas.org/content/101/45/16075</a>, <a class="reference external" href="https://arxiv.org/abs/https://www.pnas.org/content/101/45/16075.full.pdf">arXiv:https://www.pnas.org/content/101/45/16075.full.pdf</a>, <a class="reference external" href="https://doi.org/10.1073/pnas.0406666101">doi:10.1073/pnas.0406666101</a>.</p>
</dd>
<dt class="label" id="id7"><span class="brackets">PFK+08</span></dt>
<dd><p>Preethi Premkumar, Dominic Fannon, Elizabeth Kuipers, Andrew Simmons, Sophia Frangou, and Veena Kumari. Emotional decision-making and its dissociable components in schizophrenia and schizoaffective disorder: a behavioural and mri investigation. <em>Neuropsychologia</em>, 46(7):2002–2012, 2008. Part Special Issue: What is the Parietal Lobe Contribution to Human Memory? URL: <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0028393208000559">https://www.sciencedirect.com/science/article/pii/S0028393208000559</a>, <a class="reference external" href="https://doi.org/https://doi.org/10.1016/j.neuropsychologia.2008.01.022">doi:https://doi.org/10.1016/j.neuropsychologia.2008.01.022</a>.</p>
</dd>
<dt class="label" id="id2"><span class="brackets">SFH+15</span></dt>
<dd><p>Helen Steingroever, Daniel Fridberg, Annette Horstmann, Kimberly Kjome, Veena Kumari, Scott D. Lane, Tiago Maia, James McClelland, Thorsten Pachur, Preethi Premkumar, Julie Stout, Ruud Wetzels, Stacey Wood, Darrell A. Worthy, and Eric-Jan Wagenmakers. Data from 617 Healthy Participants Performing the Iowa Gambling Task: A “Many Labs” Collaboration. <em>Journal of Open Psychology Data</em>, jun 2015. URL: <a class="reference external" href="http://openpsychologydata.metajnl.com/articles/10.5334/jopd.ak/">http://openpsychologydata.metajnl.com/articles/10.5334/jopd.ak/</a>, <a class="reference external" href="https://doi.org/10.5334/JOPD.AK">doi:10.5334/JOPD.AK</a>.</p>
</dd>
<dt class="label" id="id9"><span class="brackets">SWW11</span></dt>
<dd><p>Helen Steingroever, Ruud Wetzels, and Eric-Jan Wagenmakers. Performance of healthy participants on the iowa gambling task: the impact of an alternative payoff scheme and presentation of only net outcomes. pages, 2011.</p>
</dd>
<dt class="label" id="id8"><span class="brackets">SLP11</span></dt>
<dd><p>Martin Steingroever, Helen nd Šmíra, Michael D. Lee, and Thorsten Pachur. Do intuitive and deliberate decision makers perform differently on the iowa gambling task? pages, 2011.</p>
</dd>
<dt class="label" id="id10"><span class="brackets">WVTW10</span></dt>
<dd><p>Ruud Wetzels, Joachim Vandekerckhove, Francis Tuerlinckx, and Eric-Jan Wagenmakers. Bayesian parameter estimation in the expectancy valence model of the iowa gambling task. <em>Journal of Mathematical Psychology</em>, 54(1):14–27, 2010. Contributions of Mathematical Psychology to Clinical Science and Assessment. URL: <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0022249608001132">https://www.sciencedirect.com/science/article/pii/S0022249608001132</a>, <a class="reference external" href="https://doi.org/https://doi.org/10.1016/j.jmp.2008.12.001">doi:https://doi.org/10.1016/j.jmp.2008.12.001</a>.</p>
</dd>
<dt class="label" id="id11"><span class="brackets">WBK+05</span></dt>
<dd><p>Stacey Wood, Jerome Busemeyer, Andreas Kolling, Cathy Cox, and Hasker Davis. Older adults as adaptive decision makers: evidence from the iowa gambling task. <em>Psychology and aging</em>, 20:220–5, 07 2005. <a class="reference external" href="https://doi.org/10.1037/0882-7974.20.2.220">doi:10.1037/0882-7974.20.2.220</a>.</p>
</dd>
<dt class="label" id="id12"><span class="brackets">WPB13</span></dt>
<dd><p>Darrell Worthy, Bo Pang, and Kaileigh Byrne. Decomposing the roles of perseveration and expected value representation in models of the iowa gambling task. <em>Frontiers in Psychology</em>, 4:640, 2013. URL: <a class="reference external" href="https://www.frontiersin.org/article/10.3389/fpsyg.2013.00640">https://www.frontiersin.org/article/10.3389/fpsyg.2013.00640</a>, <a class="reference external" href="https://doi.org/10.3389/fpsyg.2013.00640">doi:10.3389/fpsyg.2013.00640</a>.</p>
</dd>
</dl>
</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Seán Cummins<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>